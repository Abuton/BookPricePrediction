{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Learning').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+--------+---------+-----------+--------+------+----------+----+---------+----------+-------------+--------+------------+--------------------+---------+--------+-------+\n",
      "|                _c0|      _c1|     _c2|      _c3|        _c4|     _c5|   _c6|       _c7| _c8|      _c9|      _c10|         _c11|    _c12|        _c13|                _c14|     _c15|    _c16|   _c17|\n",
      "+-------------------+---------+--------+---------+-----------+--------+------+----------+----+---------+----------+-------------+--------+------------+--------------------+---------+--------+-------+\n",
      "|               date|    price|bedrooms|bathrooms|sqft_living|sqft_lot|floors|waterfront|view|condition|sqft_above|sqft_basement|yr_built|yr_renovated|              street|     city|statezip|country|\n",
      "|2014-05-02 00:00:00| 313000.0|     3.0|      1.5|       1340|    7912|   1.5|         0|   0|        3|      1340|            0|    1955|        2005|18810 Densmore Ave N|Shoreline|WA 98133|    USA|\n",
      "|2014-05-02 00:00:00|2384000.0|     5.0|      2.5|       3650|    9050|   2.0|         0|   4|        5|      3370|          280|    1921|           0|     709 W Blaine St|  Seattle|WA 98119|    USA|\n",
      "|2014-05-02 00:00:00| 342000.0|     3.0|      2.0|       1930|   11947|   1.0|         0|   0|        4|      1930|            0|    1966|           0|26206-26214 143rd...|     Kent|WA 98042|    USA|\n",
      "|2014-05-02 00:00:00| 420000.0|     3.0|     2.25|       2000|    8030|   1.0|         0|   0|        4|      1000|         1000|    1963|           0|     857 170th Pl NE| Bellevue|WA 98008|    USA|\n",
      "|2014-05-02 00:00:00| 550000.0|     4.0|      2.5|       1940|   10500|   1.0|         0|   0|        4|      1140|          800|    1976|        1992|   9105 170th Ave NE|  Redmond|WA 98052|    USA|\n",
      "|2014-05-02 00:00:00| 490000.0|     2.0|      1.0|        880|    6380|   1.0|         0|   0|        3|       880|            0|    1938|        1994|      522 NE 88th St|  Seattle|WA 98115|    USA|\n",
      "|2014-05-02 00:00:00| 335000.0|     2.0|      2.0|       1350|    2560|   1.0|         0|   0|        3|      1350|            0|    1976|           0|   2616 174th Ave NE|  Redmond|WA 98052|    USA|\n",
      "+-------------------+---------+--------+---------+-----------+--------+------+----------+----+---------+----------+-------------+--------+------------+--------------------+---------+--------+-------+\n",
      "only showing top 8 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(_c0='date', _c1='price', _c2='bedrooms', _c3='bathrooms', _c4='sqft_living', _c5='sqft_lot', _c6='floors', _c7='waterfront', _c8='view', _c9='condition', _c10='sqft_above', _c11='sqft_basement', _c12='yr_built', _c13='yr_renovated', _c14='street', _c15='city', _c16='statezip', _c17='country')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_c0',\n",
       " '_c1',\n",
       " '_c2',\n",
       " '_c3',\n",
       " '_c4',\n",
       " '_c5',\n",
       " '_c6',\n",
       " '_c7',\n",
       " '_c8',\n",
       " '_c9',\n",
       " '_c10',\n",
       " '_c11',\n",
       " '_c12',\n",
       " '_c13',\n",
       " '_c14',\n",
       " '_c15',\n",
       " '_c16',\n",
       " '_c17']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not so much of what i expected but will fix later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-----------------+------------------+------------------+------------------+------------------+------------------+--------------------+-------------------+------------------+------------------+------------------+-----------------+-----------------+------------+------+--------+-------+\n",
      "|summary|                _c0|              _c1|               _c2|               _c3|               _c4|               _c5|               _c6|                 _c7|                _c8|               _c9|              _c10|              _c11|             _c12|             _c13|        _c14|  _c15|    _c16|   _c17|\n",
      "+-------+-------------------+-----------------+------------------+------------------+------------------+------------------+------------------+--------------------+-------------------+------------------+------------------+------------------+-----------------+-----------------+------------+------+--------+-------+\n",
      "|  count|               4601|             4601|              4601|              4601|              4601|              4601|              4601|                4601|               4601|              4601|              4601|              4601|             4601|             4601|        4601|  4601|    4601|   4601|\n",
      "|   mean|               null|551962.9884732141|3.4008695652173913|2.1608152173913044|2139.3469565217392|14852.516086956522|1.5120652173913043|0.007173913043478261|0.24065217391304347|3.4517391304347824|1827.2654347826087|312.08152173913044|1970.786304347826|808.6082608695652|        null|  null|    null|   null|\n",
      "| stddev|               null|563834.7025471414|0.9088481155258177|0.7837810746502791| 963.2069157608655| 35884.43614480964|0.5382883772969884| 0.08440377189474309| 0.7784047172125206| 0.677229767559275| 862.1689769625966| 464.1372280666068|29.73184839009962|979.4145364007456|        null|  null|    null|   null|\n",
      "|    min|2014-05-02 00:00:00|              0.0|               0.0|               0.0|              1000|             10000|               1.0|                   0|                  0|                 1|              1000|                 0|             1900|                0|1 View Ln NE|Algona|WA 98001|    USA|\n",
      "|    max|               date|            price|          bedrooms|         bathrooms|       sqft_living|          sqft_lot|            floors|          waterfront|               view|         condition|        sqft_above|     sqft_basement|         yr_built|     yr_renovated|      street|  city|statezip|country|\n",
      "+-------+-------------------+-----------------+------------------+------------------+------------------+------------------+------------------+--------------------+-------------------+------------------+------------------+------------------+-----------------+-----------------+------------+------+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how all columns are labeled with the type string? i fixed this below let keep going"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import (StructField, StringType, IntegerType, StructType, FloatType, BooleanType, DateType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the dataschema\n",
    "data_schema = [StructField('date', DateType(), True),\n",
    "              StructField('price', IntegerType(), True),\n",
    "              StructField('bedrooms', IntegerType(), True),\n",
    "              StructField('bathrooms', FloatType(), True),\n",
    "              StructField('sqft_living', IntegerType(), True),\n",
    "              StructField('sqft_lot', IntegerType(), True),\n",
    "              StructField('floors', FloatType(), True),\n",
    "              StructField('waterfront', BooleanType(), True),\n",
    "              StructField('view', IntegerType(), True),\n",
    "              StructField('condition', IntegerType(), True),\n",
    "              StructField('sqft_above', IntegerType(), True),\n",
    "              StructField('sqft_basement', IntegerType(), True),\n",
    "              StructField('yr_built', IntegerType(), True),\n",
    "              StructField('yr_renovated', IntegerType(), True),\n",
    "              StructField('street', StringType(), True),\n",
    "              StructField('city', StringType(), True),\n",
    "              StructField('statezip', StringType(), True),\n",
    "              StructField('country', StringType(), True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(date,DateType,true),StructField(price,IntegerType,true),StructField(bedrooms,IntegerType,true),StructField(bathrooms,FloatType,true),StructField(sqft_living,IntegerType,true),StructField(sqft_lot,IntegerType,true),StructField(floors,FloatType,true),StructField(waterfront,BooleanType,true),StructField(view,IntegerType,true),StructField(condition,IntegerType,true),StructField(sqft_above,IntegerType,true),StructField(sqft_basement,IntegerType,true),StructField(yr_built,IntegerType,true),StructField(yr_renovated,IntegerType,true),StructField(street,StringType,true),StructField(city,StringType,true),StructField(statezip,StringType,true),StructField(country,StringType,true)))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_struct = StructType(fields=data_schema)\n",
    "data_struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now implement the fix\n",
    "df = spark.read.csv('data.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: string (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      " |-- bedrooms: string (nullable = true)\n",
      " |-- bathrooms: string (nullable = true)\n",
      " |-- sqft_living: string (nullable = true)\n",
      " |-- sqft_lot: string (nullable = true)\n",
      " |-- floors: string (nullable = true)\n",
      " |-- waterfront: string (nullable = true)\n",
      " |-- view: string (nullable = true)\n",
      " |-- condition: string (nullable = true)\n",
      " |-- sqft_above: string (nullable = true)\n",
      " |-- sqft_basement: string (nullable = true)\n",
      " |-- yr_built: string (nullable = true)\n",
      " |-- yr_renovated: string (nullable = true)\n",
      " |-- street: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- statezip: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all error of datatype is fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+--------+---------+-----------+--------+------+----------+----+---------+----------+-------------+--------+------------+--------------------+----------------+--------+-------+\n",
      "|               date|    price|bedrooms|bathrooms|sqft_living|sqft_lot|floors|waterfront|view|condition|sqft_above|sqft_basement|yr_built|yr_renovated|              street|            city|statezip|country|\n",
      "+-------------------+---------+--------+---------+-----------+--------+------+----------+----+---------+----------+-------------+--------+------------+--------------------+----------------+--------+-------+\n",
      "|2014-05-02 00:00:00| 313000.0|     3.0|      1.5|       1340|    7912|   1.5|         0|   0|        3|      1340|            0|    1955|        2005|18810 Densmore Ave N|       Shoreline|WA 98133|    USA|\n",
      "|2014-05-02 00:00:00|2384000.0|     5.0|      2.5|       3650|    9050|   2.0|         0|   4|        5|      3370|          280|    1921|           0|     709 W Blaine St|         Seattle|WA 98119|    USA|\n",
      "|2014-05-02 00:00:00| 342000.0|     3.0|      2.0|       1930|   11947|   1.0|         0|   0|        4|      1930|            0|    1966|           0|26206-26214 143rd...|            Kent|WA 98042|    USA|\n",
      "|2014-05-02 00:00:00| 420000.0|     3.0|     2.25|       2000|    8030|   1.0|         0|   0|        4|      1000|         1000|    1963|           0|     857 170th Pl NE|        Bellevue|WA 98008|    USA|\n",
      "|2014-05-02 00:00:00| 550000.0|     4.0|      2.5|       1940|   10500|   1.0|         0|   0|        4|      1140|          800|    1976|        1992|   9105 170th Ave NE|         Redmond|WA 98052|    USA|\n",
      "|2014-05-02 00:00:00| 490000.0|     2.0|      1.0|        880|    6380|   1.0|         0|   0|        3|       880|            0|    1938|        1994|      522 NE 88th St|         Seattle|WA 98115|    USA|\n",
      "|2014-05-02 00:00:00| 335000.0|     2.0|      2.0|       1350|    2560|   1.0|         0|   0|        3|      1350|            0|    1976|           0|   2616 174th Ave NE|         Redmond|WA 98052|    USA|\n",
      "|2014-05-02 00:00:00| 482000.0|     4.0|      2.5|       2710|   35868|   2.0|         0|   0|        3|      2710|            0|    1989|           0|   23762 SE 253rd Pl|    Maple Valley|WA 98038|    USA|\n",
      "|2014-05-02 00:00:00| 452500.0|     3.0|      2.5|       2430|   88426|   1.0|         0|   0|        4|      1570|          860|    1985|           0|46611-46625 SE 12...|      North Bend|WA 98045|    USA|\n",
      "|2014-05-02 00:00:00| 640000.0|     4.0|      2.0|       1520|    6200|   1.5|         0|   0|        3|      1520|            0|    1945|        2010|    6811 55th Ave NE|         Seattle|WA 98115|    USA|\n",
      "|2014-05-02 00:00:00| 463000.0|     3.0|     1.75|       1710|    7320|   1.0|         0|   0|        3|      1710|            0|    1948|        1994|  Burke-Gilman Trail|Lake Forest Park|WA 98155|    USA|\n",
      "|2014-05-02 00:00:00|1400000.0|     4.0|      2.5|       2920|    4000|   1.5|         0|   0|        5|      1910|         1010|    1909|        1988|3838-4098 44th Av...|         Seattle|WA 98105|    USA|\n",
      "|2014-05-02 00:00:00| 588500.0|     3.0|     1.75|       2330|   14892|   1.0|         0|   0|        3|      1970|          360|    1980|           0|    1833 220th Pl NE|       Sammamish|WA 98074|    USA|\n",
      "|2014-05-02 00:00:00| 365000.0|     3.0|      1.0|       1090|    6435|   1.0|         0|   0|        4|      1090|            0|    1955|        2009| 2504 SW Portland Ct|         Seattle|WA 98106|    USA|\n",
      "|2014-05-02 00:00:00|1200000.0|     5.0|     2.75|       2910|    9480|   1.5|         0|   0|        3|      2910|            0|    1939|        1969|    3534 46th Ave NE|         Seattle|WA 98105|    USA|\n",
      "|2014-05-02 00:00:00| 242500.0|     3.0|      1.5|       1200|    9720|   1.0|         0|   0|        4|      1200|            0|    1965|           0|   14034 SE 201st St|            Kent|WA 98042|    USA|\n",
      "|2014-05-02 00:00:00| 419000.0|     3.0|      1.5|       1570|    6700|   1.0|         0|   0|        4|      1570|            0|    1956|           0|     15424 SE 9th St|        Bellevue|WA 98007|    USA|\n",
      "|2014-05-02 00:00:00| 367500.0|     4.0|      3.0|       3110|    7231|   2.0|         0|   0|        3|      3110|            0|    1997|           0|   11224 SE 306th Pl|          Auburn|WA 98092|    USA|\n",
      "|2014-05-02 00:00:00| 257950.0|     3.0|     1.75|       1370|    5858|   1.0|         0|   0|        3|      1370|            0|    1987|        2000|     1605 S 245th Pl|      Des Moines|WA 98198|    USA|\n",
      "|2014-05-02 00:00:00| 275000.0|     3.0|      1.5|       1180|   10277|   1.0|         0|   0|        3|      1180|            0|    1983|        2009|  12425 415th Ave SE|      North Bend|WA 98045|    USA|\n",
      "+-------------------+---------+--------+---------+-----------+--------+------+----------+----+---------+----------+-------------+--------+------------+--------------------+----------------+--------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<b'country'>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.column.Column"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Price: string]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('Price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|bedrooms|\n",
      "+--------+\n",
      "|     3.0|\n",
      "|     5.0|\n",
      "|     3.0|\n",
      "|     3.0|\n",
      "|     4.0|\n",
      "|     2.0|\n",
      "|     2.0|\n",
      "|     4.0|\n",
      "|     3.0|\n",
      "|     4.0|\n",
      "|     3.0|\n",
      "|     4.0|\n",
      "|     3.0|\n",
      "|     3.0|\n",
      "|     5.0|\n",
      "|     3.0|\n",
      "|     3.0|\n",
      "|     4.0|\n",
      "|     3.0|\n",
      "|     3.0|\n",
      "+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('bedrooms').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+---------+\n",
      "|bedrooms|bathrooms|    Price|\n",
      "+--------+---------+---------+\n",
      "|     3.0|      1.5| 313000.0|\n",
      "|     5.0|      2.5|2384000.0|\n",
      "|     3.0|      2.0| 342000.0|\n",
      "|     3.0|     2.25| 420000.0|\n",
      "|     4.0|      2.5| 550000.0|\n",
      "|     2.0|      1.0| 490000.0|\n",
      "|     2.0|      2.0| 335000.0|\n",
      "|     4.0|      2.5| 482000.0|\n",
      "|     3.0|      2.5| 452500.0|\n",
      "|     4.0|      2.0| 640000.0|\n",
      "|     3.0|     1.75| 463000.0|\n",
      "|     4.0|      2.5|1400000.0|\n",
      "|     3.0|     1.75| 588500.0|\n",
      "|     3.0|      1.0| 365000.0|\n",
      "|     5.0|     2.75|1200000.0|\n",
      "|     3.0|      1.5| 242500.0|\n",
      "|     3.0|      1.5| 419000.0|\n",
      "|     4.0|      3.0| 367500.0|\n",
      "|     3.0|     1.75| 257950.0|\n",
      "|     3.0|      1.5| 275000.0|\n",
      "+--------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(['bedrooms', 'bathrooms', 'Price']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(date='2014-05-02 00:00:00', price='313000.0', bedrooms='3.0', bathrooms='1.5', sqft_living='1340', sqft_lot='7912', floors='1.5', waterfront='0', view='0', condition='3', sqft_above='1340', sqft_basement='0', yr_built='1955', yr_renovated='2005', street='18810 Densmore Ave N', city='Shoreline', statezip='WA 98133', country='USA'),\n",
       " Row(date='2014-05-02 00:00:00', price='2384000.0', bedrooms='5.0', bathrooms='2.5', sqft_living='3650', sqft_lot='9050', floors='2.0', waterfront='0', view='4', condition='5', sqft_above='3370', sqft_basement='280', yr_built='1921', yr_renovated='0', street='709 W Blaine St', city='Seattle', statezip='WA 98119', country='USA'),\n",
       " Row(date='2014-05-02 00:00:00', price='342000.0', bedrooms='3.0', bathrooms='2.0', sqft_living='1930', sqft_lot='11947', floors='1.0', waterfront='0', view='0', condition='4', sqft_above='1930', sqft_basement='0', yr_built='1966', yr_renovated='0', street='26206-26214 143rd Ave SE', city='Kent', statezip='WA 98042', country='USA'),\n",
       " Row(date='2014-05-02 00:00:00', price='420000.0', bedrooms='3.0', bathrooms='2.25', sqft_living='2000', sqft_lot='8030', floors='1.0', waterfront='0', view='0', condition='4', sqft_above='1000', sqft_basement='1000', yr_built='1963', yr_renovated='0', street='857 170th Pl NE', city='Bellevue', statezip='WA 98008', country='USA'),\n",
       " Row(date='2014-05-02 00:00:00', price='550000.0', bedrooms='4.0', bathrooms='2.5', sqft_living='1940', sqft_lot='10500', floors='1.0', waterfront='0', view='0', condition='4', sqft_above='1140', sqft_basement='800', yr_built='1976', yr_renovated='1992', street='9105 170th Ave NE', city='Redmond', statezip='WA 98052', country='USA')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(date='2014-05-02 00:00:00', price='342000.0', bedrooms='3.0', bathrooms='2.0', sqft_living='1930', sqft_lot='11947', floors='1.0', waterfront='0', view='0', condition='4', sqft_above='1930', sqft_basement='0', yr_built='1966', yr_renovated='0', street='26206-26214 143rd Ave SE', city='Kent', statezip='WA 98042', country='USA')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# since it returns a list, it possible to index\n",
    "df.head(5)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.types.Row"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df.head(5)[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a new column using withColumn(). there exist a column called yr_built which is when the house was built and year_renovated, so i created a column called yr_before_renovation which represent number of years beforehouse was renovated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('yr_before_renovation', df.yr_renovated-df.yr_built)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('houseprice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|    price|\n",
      "+---------+\n",
      "| 313000.0|\n",
      "|2384000.0|\n",
      "| 342000.0|\n",
      "| 420000.0|\n",
      "| 550000.0|\n",
      "| 490000.0|\n",
      "| 335000.0|\n",
      "| 482000.0|\n",
      "| 452500.0|\n",
      "| 640000.0|\n",
      "| 463000.0|\n",
      "|1400000.0|\n",
      "| 588500.0|\n",
      "| 365000.0|\n",
      "|1200000.0|\n",
      "| 242500.0|\n",
      "| 419000.0|\n",
      "| 367500.0|\n",
      "| 257950.0|\n",
      "| 275000.0|\n",
      "+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# select a column from the newly created table\n",
    "price = spark.sql(\"SELECT price FROM houseprice\")\n",
    "price.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select all houses with more than 3 bedrooms?\n",
    "house_with_3_more_bedrooms = spark.sql(\"SELECT * FROM houseprice WHERE bedrooms > 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+--------+---------+-----------+--------+------+----------+----+---------+----------+-------------+--------+------------+--------------------+------------+--------+-------+--------------------+\n",
      "|               date|    price|bedrooms|bathrooms|sqft_living|sqft_lot|floors|waterfront|view|condition|sqft_above|sqft_basement|yr_built|yr_renovated|              street|        city|statezip|country|yr_before_renovation|\n",
      "+-------------------+---------+--------+---------+-----------+--------+------+----------+----+---------+----------+-------------+--------+------------+--------------------+------------+--------+-------+--------------------+\n",
      "|2014-05-02 00:00:00|2384000.0|     5.0|      2.5|       3650|    9050|   2.0|         0|   4|        5|      3370|          280|    1921|           0|     709 W Blaine St|     Seattle|WA 98119|    USA|             -1921.0|\n",
      "|2014-05-02 00:00:00| 550000.0|     4.0|      2.5|       1940|   10500|   1.0|         0|   0|        4|      1140|          800|    1976|        1992|   9105 170th Ave NE|     Redmond|WA 98052|    USA|                16.0|\n",
      "|2014-05-02 00:00:00| 482000.0|     4.0|      2.5|       2710|   35868|   2.0|         0|   0|        3|      2710|            0|    1989|           0|   23762 SE 253rd Pl|Maple Valley|WA 98038|    USA|             -1989.0|\n",
      "|2014-05-02 00:00:00| 640000.0|     4.0|      2.0|       1520|    6200|   1.5|         0|   0|        3|      1520|            0|    1945|        2010|    6811 55th Ave NE|     Seattle|WA 98115|    USA|                65.0|\n",
      "|2014-05-02 00:00:00|1400000.0|     4.0|      2.5|       2920|    4000|   1.5|         0|   0|        5|      1910|         1010|    1909|        1988|3838-4098 44th Av...|     Seattle|WA 98105|    USA|                79.0|\n",
      "|2014-05-02 00:00:00|1200000.0|     5.0|     2.75|       2910|    9480|   1.5|         0|   0|        3|      2910|            0|    1939|        1969|    3534 46th Ave NE|     Seattle|WA 98105|    USA|                30.0|\n",
      "|2014-05-02 00:00:00| 367500.0|     4.0|      3.0|       3110|    7231|   2.0|         0|   0|        3|      3110|            0|    1997|           0|   11224 SE 306th Pl|      Auburn|WA 98092|    USA|             -1997.0|\n",
      "|2014-05-02 00:00:00| 435000.0|     4.0|      1.0|       1450|    8800|   1.0|         0|   0|        4|      1450|            0|    1954|        1979|   3922 154th Ave SE|    Bellevue|WA 98006|    USA|                25.0|\n",
      "|2014-05-02 00:00:00| 612500.0|     4.0|      2.5|       2730|   12261|   2.0|         0|   0|        3|      2730|            0|    1991|           0|   10212 NE 156th Pl|     Bothell|WA 98011|    USA|             -1991.0|\n",
      "|2014-05-02 00:00:00| 495000.0|     4.0|     1.75|       1600|    6380|   1.0|         0|   0|        3|      1130|          470|    1959|        1989|    2021 NE 100th St|     Seattle|WA 98125|    USA|                30.0|\n",
      "|2014-05-02 00:00:00| 698000.0|     4.0|     2.25|       2200|   11250|   1.5|         0|   0|        5|      1300|          900|    1920|           0|         1036 4th St|    Kirkland|WA 98033|    USA|             -1920.0|\n",
      "|2014-05-02 00:00:00| 675000.0|     5.0|      2.5|       2820|   67518|   2.0|         0|   0|        3|      2820|            0|    1979|        2014|   23525 SE 32nd Way|    Issaquah|WA 98029|    USA|                35.0|\n",
      "|2014-05-02 00:00:00| 382500.0|     4.0|     1.75|       1560|    8700|   1.0|         0|   0|        4|      1560|            0|    1967|           0|  14104 119th Ave NE|    Kirkland|WA 98034|    USA|             -1967.0|\n",
      "|2014-05-02 00:00:00| 499950.0|     4.0|      2.5|       2860|    3345|   2.0|         0|   0|        3|      2190|          670|    2004|        2003|  20120 137th Ave NE| Woodinville|WA 98072|    USA|                -1.0|\n",
      "|2014-05-02 00:00:00| 650000.0|     4.0|      2.0|       1820|    5000|   1.5|         0|   1|        3|      1640|          180|    1945|        2010|7201-7399 55th Av...|     Seattle|WA 98115|    USA|                65.0|\n",
      "|2014-05-02 00:00:00| 625000.0|     4.0|      2.5|       2820|    8408|   2.0|         0|   0|        3|      2820|            0|    2014|           0|    17052 4th Ave NE|   Shoreline|WA 98155|    USA|             -2014.0|\n",
      "|2014-05-02 00:00:00| 400000.0|     4.0|      2.5|       3630|   42884|   1.5|         0|   0|        3|      2300|         1330|    1979|        2014|5172-5198 Heather...|      Auburn|WA 98092|    USA|                35.0|\n",
      "|2014-05-02 00:00:00| 260000.0|     4.0|      2.0|       1480|    8625|   1.0|         0|   0|        4|      1480|            0|    1974|           0| 2019 Aberdeen Pl SE|      Renton|WA 98055|    USA|             -1974.0|\n",
      "|2014-05-02 00:00:00| 838000.0|     4.0|      2.5|       3310|   42998|   2.0|         0|   0|        3|      3310|            0|    2001|           0|   15712 NE 136th Pl|     Redmond|WA 98052|    USA|             -2001.0|\n",
      "|2014-05-02 00:00:00| 630000.0|     4.0|     2.75|       2710|   37277|   2.0|         0|   0|        3|      2710|            0|    2000|           0|   26429 SE 154th Pl|    Issaquah|WA 98027|    USA|             -2000.0|\n",
      "+-------------------+---------+--------+---------+-----------+--------+------+----------+----+---------+----------+-------------+--------+------------+--------------------+------------+--------+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "house_with_3_more_bedrooms.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|No_of_house_built|\n",
      "+-----------------+\n",
      "|               48|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# how many houses were built in the year 2000\n",
    "\n",
    "house_built_in_2000 = spark.sql(\"\"\"\n",
    "    SELECT count(*) AS No_of_house_built\n",
    "        FROM houseprice\n",
    "            WHERE yr_built = 2000\n",
    "    \n",
    "    \"\"\")\n",
    "\n",
    "house_built_in_2000.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|        avg_price|\n",
      "+-----------------+\n",
      "|743634.1423611041|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# what is the avg price for houses built in year 2000\n",
    "avg_price_house_built_in_2000 = spark.sql(\"\"\"\n",
    "    SELECT avg(price) AS avg_price\n",
    "        FROM houseprice\n",
    "            WHERE yr_built = 2000\n",
    "    \n",
    "    \"\"\")\n",
    "avg_price_house_built_in_2000.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|max_price|\n",
      "+---------+\n",
      "| 989000.0|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# what is the avg price for houses built in year 2000\n",
    "exp_house_built_in_2000 = spark.sql(\"\"\"\n",
    "    SELECT max(price) AS max_price\n",
    "        FROM houseprice\n",
    "            WHERE yr_built = 2000\n",
    "    \n",
    "    \"\"\")\n",
    "exp_house_built_in_2000.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So many Questions you can ask right?\n",
    "\n",
    "So many complex select statement you can do\n",
    "\n",
    "try them out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|No_of_houses|\n",
      "+------------+\n",
      "|         467|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# How many house has more than 3 bedrooms and built in 2001 or later\n",
    "spark.sql(\"\"\"\n",
    "    SELECT count(*) AS No_of_houses\n",
    "        FROM houseprice\n",
    "            WHERE yr_built >= 2001 AND bedrooms > 3\n",
    "    \n",
    "    \"\"\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+\n",
      "|yr_built|most_exp_house|\n",
      "+--------+--------------+\n",
      "|    1957|      999000.0|\n",
      "|    1992|      999000.0|\n",
      "|    2013|      999000.0|\n",
      "+--------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# the most expensive house is how much and what yr was it built?\n",
    "spark.sql(\"\"\"\n",
    "    SELECT yr_built, price AS most_exp_house\n",
    "        FROM houseprice\n",
    "            WHERE price = 999000.0 \n",
    "\n",
    "    \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+\n",
      "|               city|         Avg_price|\n",
      "+-------------------+------------------+\n",
      "|             Auburn|299340.44276556815|\n",
      "|       Yarrow Point|         1194837.5|\n",
      "|            Bothell| 481441.8939393939|\n",
      "|            Kenmore| 447494.0404040303|\n",
      "|      Normandy Park|506793.05555555556|\n",
      "|          Shoreline| 420392.3640469756|\n",
      "|           Issaquah| 596163.7474747486|\n",
      "|          Covington|296230.39867109305|\n",
      "|          Carnation|508751.95454545453|\n",
      "|          Sammamish| 686917.5835323659|\n",
      "|             Burien|    348947.2484985|\n",
      "|      Black Diamond|339605.55555555556|\n",
      "|         North Bend|399565.70666666003|\n",
      "|         Ravensdale| 514071.4285714286|\n",
      "|             Milton|          285000.0|\n",
      "|           Kirkland| 651583.5919080962|\n",
      "|Inglewood-Finn Hill|          425000.0|\n",
      "|         Snoqualmie| 536305.2957746478|\n",
      "|            Redmond| 667649.5347812296|\n",
      "|         Clyde Hill|1321945.4545454546|\n",
      "+-------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT city, avg(price) as Avg_price\n",
    "        FROM houseprice\n",
    "            GROUP BY city \n",
    "\n",
    "    \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|               city|\n",
      "+-------------------+\n",
      "|             Auburn|\n",
      "|       Yarrow Point|\n",
      "|            Bothell|\n",
      "|            Kenmore|\n",
      "|      Normandy Park|\n",
      "|          Shoreline|\n",
      "|           Issaquah|\n",
      "|          Covington|\n",
      "|          Carnation|\n",
      "|          Sammamish|\n",
      "|             Burien|\n",
      "|      Black Diamond|\n",
      "|         North Bend|\n",
      "|         Ravensdale|\n",
      "|             Milton|\n",
      "|           Kirkland|\n",
      "|Inglewood-Finn Hill|\n",
      "|         Snoqualmie|\n",
      "|            Redmond|\n",
      "|         Clyde Hill|\n",
      "+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"Select city from houseprice group by city\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+\n",
      "|       city|waterfront|\n",
      "+-----------+----------+\n",
      "|    Seattle|         0|\n",
      "|    Redmond|         0|\n",
      "|    Seattle|         0|\n",
      "|    Seattle|         0|\n",
      "|  Sammamish|         0|\n",
      "|    Seattle|         0|\n",
      "|    Seattle|         0|\n",
      "|    Seattle|         0|\n",
      "|    Bothell|         0|\n",
      "|    Seattle|         0|\n",
      "|   Kirkland|         0|\n",
      "|   Issaquah|         0|\n",
      "|    Seattle|         0|\n",
      "|    Seattle|         0|\n",
      "|  Shoreline|         0|\n",
      "|Federal Way|         0|\n",
      "|    Seattle|         0|\n",
      "|    Redmond|         0|\n",
      "|   Issaquah|         0|\n",
      "|  Sammamish|         0|\n",
      "+-----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# more filter\n",
    "df.filter('price > 500000').select(['city', 'waterfront']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+--------+---------+-----------+--------+------+----------+----+---------+----------+-------------+--------+------------+--------------------+----------------+--------+-------+--------------------+\n",
      "|               date|    price|bedrooms|bathrooms|sqft_living|sqft_lot|floors|waterfront|view|condition|sqft_above|sqft_basement|yr_built|yr_renovated|              street|            city|statezip|country|yr_before_renovation|\n",
      "+-------------------+---------+--------+---------+-----------+--------+------+----------+----+---------+----------+-------------+--------+------------+--------------------+----------------+--------+-------+--------------------+\n",
      "|2014-05-05 00:00:00|2280000.0|     7.0|      8.0|      13540|  307752|   3.0|         0|   4|        3|      9410|         4130|    1999|           0|    26408 NE 70th St|         Redmond|WA 98053|    USA|             -1999.0|\n",
      "|2014-05-05 00:00:00| 890000.0|     4.0|     4.25|       4420|    5750|   2.0|         0|   0|        3|      3410|         1010|    2006|           0|842 Summerhill Ri...|        Issaquah|WA 98027|    USA|             -2006.0|\n",
      "|2014-05-06 00:00:00|1870000.0|     5.0|      4.0|       4510|   15175|   2.0|         0|   0|        3|      4510|            0|    1969|        2002|     8300 SE 82nd St|   Mercer Island|WA 98040|    USA|                33.0|\n",
      "|2014-05-06 00:00:00|1800000.0|     5.0|      5.0|       4490|   10279|   2.0|         0|   0|        3|      3930|          560|    2013|        1923|   1435 104th Ave SE|        Bellevue|WA 98004|    USA|               -90.0|\n",
      "|2014-05-07 00:00:00|1150000.0|     4.0|      4.0|       4460|  103382|   2.0|         0|   0|        3|      4460|            0|    2001|           0|    25823 NE 30th Ct|         Redmond|WA 98053|    USA|             -2001.0|\n",
      "|2014-05-07 00:00:00| 599999.0|     9.0|      4.5|       3830|    6988|   2.5|         0|   0|        3|      2450|         1380|    1938|        2003| 8809 Densmore Ave N|         Seattle|WA 98103|    USA|                65.0|\n",
      "|2014-05-07 00:00:00|3200000.0|     7.0|      4.5|       6210|    8856|   2.5|         0|   2|        5|      4760|         1450|    1910|           0|   1230 Warren Ave N|         Seattle|WA 98109|    USA|             -1910.0|\n",
      "|2014-05-07 00:00:00| 540000.0|     7.0|     5.75|       3700|    7647|   2.0|         0|   1|        3|      3700|            0|    1948|        1984|15007-15299 37th ...|Lake Forest Park|WA 98155|    USA|                36.0|\n",
      "|2014-05-07 00:00:00|1532500.0|     5.0|      4.5|       4270|    8076|   2.0|         0|   0|        3|      3400|          870|    2007|           0|   11017 101st Pl NE|        Kirkland|WA 98033|    USA|             -2007.0|\n",
      "|2014-05-09 00:00:00|1157200.0|     4.0|     4.25|       5860|   52889|   2.0|         0|   0|        4|      4910|          950|    1996|           0|  13905 184th Ave NE|     Woodinville|WA 98072|    USA|             -1996.0|\n",
      "|2014-05-09 00:00:00|1702500.0|     5.0|      4.5|       5190|   23716|   2.0|         0|   2|        3|      3390|         1800|    1987|        2000|   8608 N Mercer Way|   Mercer Island|WA 98040|    USA|                13.0|\n",
      "|2014-05-09 00:00:00|2238888.0|     5.0|      6.5|       7270|  130017|   2.0|         0|   0|        3|      6420|          850|    2010|           0|    7070 270th Pl SE|        Issaquah|WA 98029|    USA|             -2010.0|\n",
      "|2014-05-13 00:00:00| 550000.0|     7.0|      4.0|       3440|    8100|   2.0|         0|   0|        3|      3440|            0|    1970|        2014|       718 N 95th St|         Seattle|WA 98103|    USA|                44.0|\n",
      "|2014-05-13 00:00:00|1400000.0|     5.0|     4.25|       3530|    7924|   2.0|         0|   0|        3|      3530|            0|    2001|           0|    2278 72nd Ave SE|   Mercer Island|WA 98040|    USA|             -2001.0|\n",
      "|2014-05-14 00:00:00| 966000.0|     5.0|      4.5|       3810|    8019|   2.0|         0|   0|        3|      3810|            0|    2008|           0|    2033 211th Pl SE|       Sammamish|WA 98075|    USA|             -2008.0|\n",
      "|2014-05-15 00:00:00|1000000.0|     5.0|     4.25|       3920|   16258|   2.0|         0|   0|        3|      2900|         1020|    1990|        2009|   2548 111th Ave SE|        Bellevue|WA 98004|    USA|                19.0|\n",
      "|2014-05-16 00:00:00|2000000.0|     5.0|     4.25|       6490|   10862|   2.0|         0|   3|        4|      3940|         2550|    1991|           0|   4080 E Mercer Way|   Mercer Island|WA 98040|    USA|             -1991.0|\n",
      "|2014-05-20 00:00:00| 300000.0|     6.0|     5.25|       2860|    5682|   2.0|         0|   0|        3|      2860|            0|    1978|           0|       606 5th St SE|          Auburn|WA 98002|    USA|             -1978.0|\n",
      "|2014-05-21 00:00:00| 975000.0|     5.0|      4.0|       4850|   36450|   2.0|         0|   0|        3|      4850|            0|    1977|        2004|    13600 NE 36th Pl|        Bellevue|WA 98005|    USA|                27.0|\n",
      "|2014-05-21 00:00:00|2700000.0|     5.0|     4.75|       5305|    8401|   2.0|         0|   2|        3|      3745|         1560|    2005|           0|       1010 6th St W|        Kirkland|WA 98033|    USA|             -2005.0|\n",
      "+-------------------+---------+--------+---------+-----------+--------+------+----------+----+---------+----------+-------------+--------+------------+--------------------+----------------+--------+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter((df['floors'] > 1.5) & (df['bathrooms'] > 3)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.group.GroupedData at 0x26ce7d60248>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter((df['floors'] > 1.5) & (df['bathrooms'] > 3)).groupby('city')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+--------+---------+-----------+--------+------+----------+----+---------+----------+-------------+--------+------------+--------------------+----------------+--------+-------+\n",
      "|               date|    price|bedrooms|bathrooms|sqft_living|sqft_lot|floors|waterfront|view|condition|sqft_above|sqft_basement|yr_built|yr_renovated|              street|            city|statezip|country|\n",
      "+-------------------+---------+--------+---------+-----------+--------+------+----------+----+---------+----------+-------------+--------+------------+--------------------+----------------+--------+-------+\n",
      "|2014-05-02 00:00:00| 313000.0|     3.0|      1.5|       1340|    7912|   1.5|         0|   0|        3|      1340|            0|    1955|        2005|18810 Densmore Ave N|       Shoreline|WA 98133|    USA|\n",
      "|2014-05-02 00:00:00|2384000.0|     5.0|      2.5|       3650|    9050|   2.0|         0|   4|        5|      3370|          280|    1921|           0|     709 W Blaine St|         Seattle|WA 98119|    USA|\n",
      "|2014-05-02 00:00:00| 342000.0|     3.0|      2.0|       1930|   11947|   1.0|         0|   0|        4|      1930|            0|    1966|           0|26206-26214 143rd...|            Kent|WA 98042|    USA|\n",
      "|2014-05-02 00:00:00| 420000.0|     3.0|     2.25|       2000|    8030|   1.0|         0|   0|        4|      1000|         1000|    1963|           0|     857 170th Pl NE|        Bellevue|WA 98008|    USA|\n",
      "|2014-05-02 00:00:00| 550000.0|     4.0|      2.5|       1940|   10500|   1.0|         0|   0|        4|      1140|          800|    1976|        1992|   9105 170th Ave NE|         Redmond|WA 98052|    USA|\n",
      "|2014-05-02 00:00:00| 490000.0|     2.0|      1.0|        880|    6380|   1.0|         0|   0|        3|       880|            0|    1938|        1994|      522 NE 88th St|         Seattle|WA 98115|    USA|\n",
      "|2014-05-02 00:00:00| 335000.0|     2.0|      2.0|       1350|    2560|   1.0|         0|   0|        3|      1350|            0|    1976|           0|   2616 174th Ave NE|         Redmond|WA 98052|    USA|\n",
      "|2014-05-02 00:00:00| 482000.0|     4.0|      2.5|       2710|   35868|   2.0|         0|   0|        3|      2710|            0|    1989|           0|   23762 SE 253rd Pl|    Maple Valley|WA 98038|    USA|\n",
      "|2014-05-02 00:00:00| 452500.0|     3.0|      2.5|       2430|   88426|   1.0|         0|   0|        4|      1570|          860|    1985|           0|46611-46625 SE 12...|      North Bend|WA 98045|    USA|\n",
      "|2014-05-02 00:00:00| 640000.0|     4.0|      2.0|       1520|    6200|   1.5|         0|   0|        3|      1520|            0|    1945|        2010|    6811 55th Ave NE|         Seattle|WA 98115|    USA|\n",
      "|2014-05-02 00:00:00| 463000.0|     3.0|     1.75|       1710|    7320|   1.0|         0|   0|        3|      1710|            0|    1948|        1994|  Burke-Gilman Trail|Lake Forest Park|WA 98155|    USA|\n",
      "|2014-05-02 00:00:00|1400000.0|     4.0|      2.5|       2920|    4000|   1.5|         0|   0|        5|      1910|         1010|    1909|        1988|3838-4098 44th Av...|         Seattle|WA 98105|    USA|\n",
      "|2014-05-02 00:00:00| 588500.0|     3.0|     1.75|       2330|   14892|   1.0|         0|   0|        3|      1970|          360|    1980|           0|    1833 220th Pl NE|       Sammamish|WA 98074|    USA|\n",
      "|2014-05-02 00:00:00| 365000.0|     3.0|      1.0|       1090|    6435|   1.0|         0|   0|        4|      1090|            0|    1955|        2009| 2504 SW Portland Ct|         Seattle|WA 98106|    USA|\n",
      "|2014-05-02 00:00:00|1200000.0|     5.0|     2.75|       2910|    9480|   1.5|         0|   0|        3|      2910|            0|    1939|        1969|    3534 46th Ave NE|         Seattle|WA 98105|    USA|\n",
      "|2014-05-02 00:00:00| 242500.0|     3.0|      1.5|       1200|    9720|   1.0|         0|   0|        4|      1200|            0|    1965|           0|   14034 SE 201st St|            Kent|WA 98042|    USA|\n",
      "|2014-05-02 00:00:00| 419000.0|     3.0|      1.5|       1570|    6700|   1.0|         0|   0|        4|      1570|            0|    1956|           0|     15424 SE 9th St|        Bellevue|WA 98007|    USA|\n",
      "|2014-05-02 00:00:00| 367500.0|     4.0|      3.0|       3110|    7231|   2.0|         0|   0|        3|      3110|            0|    1997|           0|   11224 SE 306th Pl|          Auburn|WA 98092|    USA|\n",
      "|2014-05-02 00:00:00| 257950.0|     3.0|     1.75|       1370|    5858|   1.0|         0|   0|        3|      1370|            0|    1987|        2000|     1605 S 245th Pl|      Des Moines|WA 98198|    USA|\n",
      "|2014-05-02 00:00:00| 275000.0|     3.0|      1.5|       1180|   10277|   1.0|         0|   0|        3|      1180|            0|    1983|        2009|  12425 415th Ave SE|      North Bend|WA 98045|    USA|\n",
      "+-------------------+---------+--------+---------+-----------+--------+------+----------+----+---------+----------+-------------+--------+------------+--------------------+----------------+--------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = spark.read.csv('data.csv', inferSchema=True, header=True)\n",
    "\n",
    "a.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: timestamp (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- bedrooms: double (nullable = true)\n",
      " |-- bathrooms: double (nullable = true)\n",
      " |-- sqft_living: integer (nullable = true)\n",
      " |-- sqft_lot: integer (nullable = true)\n",
      " |-- floors: double (nullable = true)\n",
      " |-- waterfront: integer (nullable = true)\n",
      " |-- view: integer (nullable = true)\n",
      " |-- condition: integer (nullable = true)\n",
      " |-- sqft_above: integer (nullable = true)\n",
      " |-- sqft_basement: integer (nullable = true)\n",
      " |-- yr_built: integer (nullable = true)\n",
      " |-- yr_renovated: integer (nullable = true)\n",
      " |-- street: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- statezip: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+------------------+------------------+------------------+------------------+------------------+--------------------+-------------------+------------------+------------------+------------------+------------------+------------------+\n",
      "|               city|        avg(price)|     avg(bedrooms)|    avg(bathrooms)|  avg(sqft_living)|     avg(sqft_lot)|       avg(floors)|     avg(waterfront)|          avg(view)|    avg(condition)|   avg(sqft_above)|avg(sqft_basement)|     avg(yr_built)| avg(yr_renovated)|\n",
      "+-------------------+------------------+------------------+------------------+------------------+------------------+------------------+--------------------+-------------------+------------------+------------------+------------------+------------------+------------------+\n",
      "|             Auburn|299340.44276556815|3.4204545454545454|2.0923295454545454|2019.5795454545455|24999.221590909092|1.4488636363636365|                 0.0|              0.125| 3.409090909090909|           1862.25|157.32954545454547|1980.7954545454545| 725.7613636363636|\n",
      "|       Yarrow Point|         1194837.5|              3.75|            1.9375|            2472.5|           13373.0|               2.0|                 0.0|                0.5|              3.75|            2472.5|               0.0|           1965.75|             992.0|\n",
      "|            Bothell| 481441.8939393939| 3.606060606060606|2.4318181818181817|2319.3939393939395| 9060.181818181818|               1.5|                 0.0|                0.0|3.1515151515151514| 1957.878787878788| 361.5151515151515|1982.6969696969697| 727.1515151515151|\n",
      "|            Kenmore| 447494.0404040303|3.5606060606060606| 2.196969696969697| 2110.530303030303| 12902.69696969697|1.4848484848484849|                 0.0|0.10606060606060606| 3.378787878787879|1792.0454545454545| 318.4848484848485|1979.3636363636363| 695.3939393939394|\n",
      "|      Normandy Park|506793.05555555556|3.4444444444444446| 2.013888888888889| 2093.277777777778|13441.277777777777|1.0555555555555556| 0.05555555555555555| 0.7777777777777778| 3.888888888888889|1717.7222222222222|375.55555555555554|1960.7222222222222|1107.7222222222222|\n",
      "|          Shoreline| 420392.3640469756|3.3089430894308944|1.8008130081300813|1774.8373983739837| 9102.365853658537|1.2195121951219512|                 0.0|0.22764227642276422|3.6422764227642275|1489.5528455284552| 285.2845528455285|1959.7642276422764| 1215.959349593496|\n",
      "|           Issaquah| 596163.7474747486|3.5614973262032086| 2.593582887700535|2458.8449197860964|24724.074866310162|1.7994652406417113|  0.0053475935828877|0.09090909090909091|3.3101604278074865| 2122.695187165775|336.14973262032083| 1992.716577540107|405.80213903743316|\n",
      "|          Covington|296230.39867109305|3.3255813953488373|1.9709302325581395|1792.5581395348838|12122.976744186046|1.3488372093023255|                 0.0|                0.0|3.6511627906976742|1648.8372093023256|143.72093023255815|1984.6511627906978| 558.1162790697674|\n",
      "|          Carnation|508751.95454545453| 3.090909090909091|2.1704545454545454|2392.4545454545455| 64873.77272727273|1.5227272727272727|                 0.0| 0.3181818181818182| 3.090909090909091| 2205.181818181818|187.27272727272728|1982.8181818181818| 727.3181818181819|\n",
      "|          Sammamish| 686917.5835323659|3.7257142857142855|2.5785714285714287|           2830.12|16127.331428571428|1.7685714285714285|0.017142857142857144|0.19428571428571428| 3.165714285714286| 2664.062857142857|166.05714285714285|1991.6685714285713| 696.6857142857143|\n",
      "|             Burien|    348947.2484985|3.3378378378378377|1.7466216216216217| 1815.337837837838|12158.554054054053|1.2094594594594594| 0.04054054054054054| 0.5405405405405406| 3.554054054054054| 1468.445945945946| 346.8918918918919|1957.3513513513512| 1183.945945945946|\n",
      "|      Black Diamond|339605.55555555556|3.2222222222222223|              1.75|1863.3333333333333|25006.666666666668|1.3888888888888888|                 0.0|                0.0|3.2222222222222223|1807.7777777777778| 55.55555555555556|1978.6666666666667|1107.3333333333333|\n",
      "|         North Bend|399565.70666666003|               3.3|               2.2|            1995.4|          32053.68|              1.57|                 0.0|               0.22|              3.32|            1879.2|             116.2|           1983.28|             909.7|\n",
      "|         Ravensdale| 514071.4285714286|3.4285714285714284|2.0357142857142856|2612.8571428571427|132017.14285714287|1.7142857142857142|                 0.0|                0.0| 3.142857142857143|2612.8571428571427|               0.0|            1986.0| 571.5714285714286|\n",
      "|             Milton|          285000.0|               3.0|              1.75|            1255.0|           10150.0|               1.0|                 0.0|                0.0|               4.0|            1255.0|               0.0|            1983.0|               0.0|\n",
      "|           Kirkland| 651583.5919080962|3.5401069518716577|2.3275401069518717|  2259.48128342246| 10317.70588235294|1.4598930481283423|  0.0053475935828877| 0.1657754010695187|3.4919786096256686| 1955.149732620321|  304.331550802139| 1979.385026737968| 662.9197860962566|\n",
      "|Inglewood-Finn Hill|          425000.0|               4.0|               2.0|            1520.0|            7983.0|               1.0|                 0.0|                0.0|               5.0|            1520.0|               0.0|            1967.0|               0.0|\n",
      "|         Snoqualmie| 536305.2957746478|3.5774647887323945|2.6338028169014085| 2716.056338028169|17616.535211267605|1.8732394366197183|                 0.0|0.28169014084507044| 3.028169014084507| 2607.323943661972|108.73239436619718|1999.6338028169014| 444.1267605633803|\n",
      "|            Redmond| 667649.5347812296| 3.421276595744681| 2.380851063829787|2491.7617021276596|23936.191489361703|1.5638297872340425| 0.00851063829787234|0.05531914893617021|3.2382978723404254| 2288.655319148936|203.10638297872342|1989.5021276595744| 526.6765957446809|\n",
      "|         Clyde Hill|1321945.4545454546| 4.181818181818182|2.6136363636363638| 3620.909090909091|19633.909090909092|1.1818181818181819|                 0.0| 0.8181818181818182|3.5454545454545454|2522.7272727272725|1098.1818181818182|1964.4545454545455|            1092.0|\n",
      "+-------------------+------------------+------------------+------------------+------------------+------------------+------------------+--------------------+-------------------+------------------+------------------+------------------+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a.groupBy('city').mean().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+\n",
      "|               city|        avg(price)|\n",
      "+-------------------+------------------+\n",
      "|             Auburn|299340.44276556815|\n",
      "|       Yarrow Point|         1194837.5|\n",
      "|            Bothell| 481441.8939393939|\n",
      "|            Kenmore| 447494.0404040303|\n",
      "|      Normandy Park|506793.05555555556|\n",
      "|          Shoreline| 420392.3640469756|\n",
      "|           Issaquah| 596163.7474747486|\n",
      "|          Covington|296230.39867109305|\n",
      "|          Carnation|508751.95454545453|\n",
      "|          Sammamish| 686917.5835323659|\n",
      "|             Burien|    348947.2484985|\n",
      "|      Black Diamond|339605.55555555556|\n",
      "|         North Bend|399565.70666666003|\n",
      "|         Ravensdale| 514071.4285714286|\n",
      "|             Milton|          285000.0|\n",
      "|           Kirkland| 651583.5919080962|\n",
      "|Inglewood-Finn Hill|          425000.0|\n",
      "|         Snoqualmie| 536305.2957746478|\n",
      "|            Redmond| 667649.5347812296|\n",
      "|         Clyde Hill|1321945.4545454546|\n",
      "+-------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(['price', 'city', 'bedrooms', 'bathrooms', 'floors']).groupBy('city').agg({'price':'mean'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+\n",
      "|               city|count|\n",
      "+-------------------+-----+\n",
      "|             Auburn|  176|\n",
      "|       Yarrow Point|    4|\n",
      "|            Bothell|   33|\n",
      "|            Kenmore|   66|\n",
      "|      Normandy Park|   18|\n",
      "|          Shoreline|  123|\n",
      "|           Issaquah|  187|\n",
      "|          Covington|   43|\n",
      "|          Carnation|   22|\n",
      "|          Sammamish|  175|\n",
      "|             Burien|   74|\n",
      "|      Black Diamond|    9|\n",
      "|         North Bend|   50|\n",
      "|         Ravensdale|    7|\n",
      "|             Milton|    2|\n",
      "|           Kirkland|  187|\n",
      "|Inglewood-Finn Hill|    1|\n",
      "|         Snoqualmie|   71|\n",
      "|            Redmond|  235|\n",
      "|         Clyde Hill|   11|\n",
      "+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('city').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import countDistinct, avg, stddev, format_number, format_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|       avg(price)|\n",
      "+-----------------+\n",
      "|551962.9884732141|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(avg('price')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|stddev_samp(price)|\n",
      "+------------------+\n",
      "| 563834.7025471414|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(stddev('price')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|  avg(sqft_living)|\n",
      "+------------------+\n",
      "|2139.3469565217392|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(avg('sqft_living')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|Avg_sqft_living|\n",
      "+---------------+\n",
      "|       2,139.35|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avg_sqft_living = df.select(avg('sqft_living'))\n",
    "avg_sqft_living.select(format_number('avg(sqft_living)', 2).alias('Avg_sqft_living')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------+\n",
      "|               city|city_avg_price|\n",
      "+-------------------+--------------+\n",
      "|             Algona|    207,288.00|\n",
      "|            Pacific|    225,233.33|\n",
      "|          Skykomish|    233,000.00|\n",
      "|             SeaTac|    245,290.62|\n",
      "|             Milton|    285,000.00|\n",
      "|        Federal Way|    289,887.70|\n",
      "|          Covington|    296,230.40|\n",
      "|             Auburn|    299,340.44|\n",
      "|         Des Moines|    304,992.55|\n",
      "|           Enumclaw|    307,614.58|\n",
      "|            Tukwila|    308,290.07|\n",
      "|       Maple Valley|    336,474.91|\n",
      "|      Black Diamond|    339,605.56|\n",
      "|             Burien|    348,947.25|\n",
      "|             Renton|    377,040.97|\n",
      "|         North Bend|    399,565.71|\n",
      "|             Duvall|    403,994.13|\n",
      "|          Shoreline|    420,392.36|\n",
      "|Inglewood-Finn Hill|    425,000.00|\n",
      "|               Kent|    439,492.44|\n",
      "+-------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "city_avg_price = df.select(['price', 'city', 'bedrooms', 'bathrooms', 'floors']).groupBy('city')\\\n",
    "            .agg({'price':'mean'})\\\n",
    "                .orderBy('avg(price)',\n",
    "                         asc=True)\n",
    "city_avg_price.select(['city', format_number('avg(price)', 2).alias('city_avg_price')]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with NULL values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+--------+---------+-----------+--------+------+----------+----+---------+----------+-------------+--------+------------+--------------------+----------------+--------+-------+--------------------+\n",
      "|               date|    price|bedrooms|bathrooms|sqft_living|sqft_lot|floors|waterfront|view|condition|sqft_above|sqft_basement|yr_built|yr_renovated|              street|            city|statezip|country|yr_before_renovation|\n",
      "+-------------------+---------+--------+---------+-----------+--------+------+----------+----+---------+----------+-------------+--------+------------+--------------------+----------------+--------+-------+--------------------+\n",
      "|2014-05-02 00:00:00| 313000.0|     3.0|      1.5|       1340|    7912|   1.5|         0|   0|        3|      1340|            0|    1955|        2005|18810 Densmore Ave N|       Shoreline|WA 98133|    USA|                50.0|\n",
      "|2014-05-02 00:00:00|2384000.0|     5.0|      2.5|       3650|    9050|   2.0|         0|   4|        5|      3370|          280|    1921|           0|     709 W Blaine St|         Seattle|WA 98119|    USA|             -1921.0|\n",
      "|2014-05-02 00:00:00| 342000.0|     3.0|      2.0|       1930|   11947|   1.0|         0|   0|        4|      1930|            0|    1966|           0|26206-26214 143rd...|            Kent|WA 98042|    USA|             -1966.0|\n",
      "|2014-05-02 00:00:00| 420000.0|     3.0|     2.25|       2000|    8030|   1.0|         0|   0|        4|      1000|         1000|    1963|           0|     857 170th Pl NE|        Bellevue|WA 98008|    USA|             -1963.0|\n",
      "|2014-05-02 00:00:00| 550000.0|     4.0|      2.5|       1940|   10500|   1.0|         0|   0|        4|      1140|          800|    1976|        1992|   9105 170th Ave NE|         Redmond|WA 98052|    USA|                16.0|\n",
      "|2014-05-02 00:00:00| 490000.0|     2.0|      1.0|        880|    6380|   1.0|         0|   0|        3|       880|            0|    1938|        1994|      522 NE 88th St|         Seattle|WA 98115|    USA|                56.0|\n",
      "|2014-05-02 00:00:00| 335000.0|     2.0|      2.0|       1350|    2560|   1.0|         0|   0|        3|      1350|            0|    1976|           0|   2616 174th Ave NE|         Redmond|WA 98052|    USA|             -1976.0|\n",
      "|2014-05-02 00:00:00| 482000.0|     4.0|      2.5|       2710|   35868|   2.0|         0|   0|        3|      2710|            0|    1989|           0|   23762 SE 253rd Pl|    Maple Valley|WA 98038|    USA|             -1989.0|\n",
      "|2014-05-02 00:00:00| 452500.0|     3.0|      2.5|       2430|   88426|   1.0|         0|   0|        4|      1570|          860|    1985|           0|46611-46625 SE 12...|      North Bend|WA 98045|    USA|             -1985.0|\n",
      "|2014-05-02 00:00:00| 640000.0|     4.0|      2.0|       1520|    6200|   1.5|         0|   0|        3|      1520|            0|    1945|        2010|    6811 55th Ave NE|         Seattle|WA 98115|    USA|                65.0|\n",
      "|2014-05-02 00:00:00| 463000.0|     3.0|     1.75|       1710|    7320|   1.0|         0|   0|        3|      1710|            0|    1948|        1994|  Burke-Gilman Trail|Lake Forest Park|WA 98155|    USA|                46.0|\n",
      "|2014-05-02 00:00:00|1400000.0|     4.0|      2.5|       2920|    4000|   1.5|         0|   0|        5|      1910|         1010|    1909|        1988|3838-4098 44th Av...|         Seattle|WA 98105|    USA|                79.0|\n",
      "|2014-05-02 00:00:00| 588500.0|     3.0|     1.75|       2330|   14892|   1.0|         0|   0|        3|      1970|          360|    1980|           0|    1833 220th Pl NE|       Sammamish|WA 98074|    USA|             -1980.0|\n",
      "|2014-05-02 00:00:00| 365000.0|     3.0|      1.0|       1090|    6435|   1.0|         0|   0|        4|      1090|            0|    1955|        2009| 2504 SW Portland Ct|         Seattle|WA 98106|    USA|                54.0|\n",
      "|2014-05-02 00:00:00|1200000.0|     5.0|     2.75|       2910|    9480|   1.5|         0|   0|        3|      2910|            0|    1939|        1969|    3534 46th Ave NE|         Seattle|WA 98105|    USA|                30.0|\n",
      "|2014-05-02 00:00:00| 242500.0|     3.0|      1.5|       1200|    9720|   1.0|         0|   0|        4|      1200|            0|    1965|           0|   14034 SE 201st St|            Kent|WA 98042|    USA|             -1965.0|\n",
      "|2014-05-02 00:00:00| 419000.0|     3.0|      1.5|       1570|    6700|   1.0|         0|   0|        4|      1570|            0|    1956|           0|     15424 SE 9th St|        Bellevue|WA 98007|    USA|             -1956.0|\n",
      "|2014-05-02 00:00:00| 367500.0|     4.0|      3.0|       3110|    7231|   2.0|         0|   0|        3|      3110|            0|    1997|           0|   11224 SE 306th Pl|          Auburn|WA 98092|    USA|             -1997.0|\n",
      "|2014-05-02 00:00:00| 257950.0|     3.0|     1.75|       1370|    5858|   1.0|         0|   0|        3|      1370|            0|    1987|        2000|     1605 S 245th Pl|      Des Moines|WA 98198|    USA|                13.0|\n",
      "|2014-05-02 00:00:00| 275000.0|     3.0|      1.5|       1180|   10277|   1.0|         0|   0|        3|      1180|            0|    1983|        2009|  12425 415th Ave SE|      North Bend|WA 98045|    USA|                26.0|\n",
      "+-------------------+---------+--------+---------+-----------+--------+------+----------+----+---------+----------+-------------+--------+------------+--------------------+----------------+--------+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+--------+---------+-----------+--------+------+----------+----+---------+----------+-------------+--------+------------+--------------------+----------------+--------+-------+--------------------+\n",
      "|               date|    price|bedrooms|bathrooms|sqft_living|sqft_lot|floors|waterfront|view|condition|sqft_above|sqft_basement|yr_built|yr_renovated|              street|            city|statezip|country|yr_before_renovation|\n",
      "+-------------------+---------+--------+---------+-----------+--------+------+----------+----+---------+----------+-------------+--------+------------+--------------------+----------------+--------+-------+--------------------+\n",
      "|2014-05-02 00:00:00| 313000.0|     3.0|      1.5|       1340|    7912|   1.5|         0|   0|        3|      1340|            0|    1955|        2005|18810 Densmore Ave N|       Shoreline|WA 98133|    USA|                50.0|\n",
      "|2014-05-02 00:00:00|2384000.0|     5.0|      2.5|       3650|    9050|   2.0|         0|   4|        5|      3370|          280|    1921|           0|     709 W Blaine St|         Seattle|WA 98119|    USA|             -1921.0|\n",
      "|2014-05-02 00:00:00| 342000.0|     3.0|      2.0|       1930|   11947|   1.0|         0|   0|        4|      1930|            0|    1966|           0|26206-26214 143rd...|            Kent|WA 98042|    USA|             -1966.0|\n",
      "|2014-05-02 00:00:00| 420000.0|     3.0|     2.25|       2000|    8030|   1.0|         0|   0|        4|      1000|         1000|    1963|           0|     857 170th Pl NE|        Bellevue|WA 98008|    USA|             -1963.0|\n",
      "|2014-05-02 00:00:00| 550000.0|     4.0|      2.5|       1940|   10500|   1.0|         0|   0|        4|      1140|          800|    1976|        1992|   9105 170th Ave NE|         Redmond|WA 98052|    USA|                16.0|\n",
      "|2014-05-02 00:00:00| 490000.0|     2.0|      1.0|        880|    6380|   1.0|         0|   0|        3|       880|            0|    1938|        1994|      522 NE 88th St|         Seattle|WA 98115|    USA|                56.0|\n",
      "|2014-05-02 00:00:00| 335000.0|     2.0|      2.0|       1350|    2560|   1.0|         0|   0|        3|      1350|            0|    1976|           0|   2616 174th Ave NE|         Redmond|WA 98052|    USA|             -1976.0|\n",
      "|2014-05-02 00:00:00| 482000.0|     4.0|      2.5|       2710|   35868|   2.0|         0|   0|        3|      2710|            0|    1989|           0|   23762 SE 253rd Pl|    Maple Valley|WA 98038|    USA|             -1989.0|\n",
      "|2014-05-02 00:00:00| 452500.0|     3.0|      2.5|       2430|   88426|   1.0|         0|   0|        4|      1570|          860|    1985|           0|46611-46625 SE 12...|      North Bend|WA 98045|    USA|             -1985.0|\n",
      "|2014-05-02 00:00:00| 640000.0|     4.0|      2.0|       1520|    6200|   1.5|         0|   0|        3|      1520|            0|    1945|        2010|    6811 55th Ave NE|         Seattle|WA 98115|    USA|                65.0|\n",
      "|2014-05-02 00:00:00| 463000.0|     3.0|     1.75|       1710|    7320|   1.0|         0|   0|        3|      1710|            0|    1948|        1994|  Burke-Gilman Trail|Lake Forest Park|WA 98155|    USA|                46.0|\n",
      "|2014-05-02 00:00:00|1400000.0|     4.0|      2.5|       2920|    4000|   1.5|         0|   0|        5|      1910|         1010|    1909|        1988|3838-4098 44th Av...|         Seattle|WA 98105|    USA|                79.0|\n",
      "|2014-05-02 00:00:00| 588500.0|     3.0|     1.75|       2330|   14892|   1.0|         0|   0|        3|      1970|          360|    1980|           0|    1833 220th Pl NE|       Sammamish|WA 98074|    USA|             -1980.0|\n",
      "|2014-05-02 00:00:00| 365000.0|     3.0|      1.0|       1090|    6435|   1.0|         0|   0|        4|      1090|            0|    1955|        2009| 2504 SW Portland Ct|         Seattle|WA 98106|    USA|                54.0|\n",
      "|2014-05-02 00:00:00|1200000.0|     5.0|     2.75|       2910|    9480|   1.5|         0|   0|        3|      2910|            0|    1939|        1969|    3534 46th Ave NE|         Seattle|WA 98105|    USA|                30.0|\n",
      "|2014-05-02 00:00:00| 242500.0|     3.0|      1.5|       1200|    9720|   1.0|         0|   0|        4|      1200|            0|    1965|           0|   14034 SE 201st St|            Kent|WA 98042|    USA|             -1965.0|\n",
      "|2014-05-02 00:00:00| 419000.0|     3.0|      1.5|       1570|    6700|   1.0|         0|   0|        4|      1570|            0|    1956|           0|     15424 SE 9th St|        Bellevue|WA 98007|    USA|             -1956.0|\n",
      "|2014-05-02 00:00:00| 367500.0|     4.0|      3.0|       3110|    7231|   2.0|         0|   0|        3|      3110|            0|    1997|           0|   11224 SE 306th Pl|          Auburn|WA 98092|    USA|             -1997.0|\n",
      "|2014-05-02 00:00:00| 257950.0|     3.0|     1.75|       1370|    5858|   1.0|         0|   0|        3|      1370|            0|    1987|        2000|     1605 S 245th Pl|      Des Moines|WA 98198|    USA|                13.0|\n",
      "|2014-05-02 00:00:00| 275000.0|     3.0|      1.5|       1180|   10277|   1.0|         0|   0|        3|      1180|            0|    1983|        2009|  12425 415th Ave SE|      North Bend|WA 98045|    USA|                26.0|\n",
      "+-------------------+---------+--------+---------+-----------+--------+------+----------+----+---------+----------+-------------+--------+------------+--------------------+----------------+--------+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+--------+---------+-----------+--------+------+----------+----+---------+----------+-------------+--------+------------+--------------------+----------------+--------+-------+--------------------+\n",
      "|               date|    price|bedrooms|bathrooms|sqft_living|sqft_lot|floors|waterfront|view|condition|sqft_above|sqft_basement|yr_built|yr_renovated|              street|            city|statezip|country|yr_before_renovation|\n",
      "+-------------------+---------+--------+---------+-----------+--------+------+----------+----+---------+----------+-------------+--------+------------+--------------------+----------------+--------+-------+--------------------+\n",
      "|2014-05-02 00:00:00| 313000.0|     3.0|      1.5|       1340|    7912|   1.5|         0|   0|        3|      1340|            0|    1955|        2005|18810 Densmore Ave N|       Shoreline|WA 98133|    USA|                50.0|\n",
      "|2014-05-02 00:00:00|2384000.0|     5.0|      2.5|       3650|    9050|   2.0|         0|   4|        5|      3370|          280|    1921|           0|     709 W Blaine St|         Seattle|WA 98119|    USA|             -1921.0|\n",
      "|2014-05-02 00:00:00| 342000.0|     3.0|      2.0|       1930|   11947|   1.0|         0|   0|        4|      1930|            0|    1966|           0|26206-26214 143rd...|            Kent|WA 98042|    USA|             -1966.0|\n",
      "|2014-05-02 00:00:00| 420000.0|     3.0|     2.25|       2000|    8030|   1.0|         0|   0|        4|      1000|         1000|    1963|           0|     857 170th Pl NE|        Bellevue|WA 98008|    USA|             -1963.0|\n",
      "|2014-05-02 00:00:00| 550000.0|     4.0|      2.5|       1940|   10500|   1.0|         0|   0|        4|      1140|          800|    1976|        1992|   9105 170th Ave NE|         Redmond|WA 98052|    USA|                16.0|\n",
      "|2014-05-02 00:00:00| 490000.0|     2.0|      1.0|        880|    6380|   1.0|         0|   0|        3|       880|            0|    1938|        1994|      522 NE 88th St|         Seattle|WA 98115|    USA|                56.0|\n",
      "|2014-05-02 00:00:00| 335000.0|     2.0|      2.0|       1350|    2560|   1.0|         0|   0|        3|      1350|            0|    1976|           0|   2616 174th Ave NE|         Redmond|WA 98052|    USA|             -1976.0|\n",
      "|2014-05-02 00:00:00| 482000.0|     4.0|      2.5|       2710|   35868|   2.0|         0|   0|        3|      2710|            0|    1989|           0|   23762 SE 253rd Pl|    Maple Valley|WA 98038|    USA|             -1989.0|\n",
      "|2014-05-02 00:00:00| 452500.0|     3.0|      2.5|       2430|   88426|   1.0|         0|   0|        4|      1570|          860|    1985|           0|46611-46625 SE 12...|      North Bend|WA 98045|    USA|             -1985.0|\n",
      "|2014-05-02 00:00:00| 640000.0|     4.0|      2.0|       1520|    6200|   1.5|         0|   0|        3|      1520|            0|    1945|        2010|    6811 55th Ave NE|         Seattle|WA 98115|    USA|                65.0|\n",
      "|2014-05-02 00:00:00| 463000.0|     3.0|     1.75|       1710|    7320|   1.0|         0|   0|        3|      1710|            0|    1948|        1994|  Burke-Gilman Trail|Lake Forest Park|WA 98155|    USA|                46.0|\n",
      "|2014-05-02 00:00:00|1400000.0|     4.0|      2.5|       2920|    4000|   1.5|         0|   0|        5|      1910|         1010|    1909|        1988|3838-4098 44th Av...|         Seattle|WA 98105|    USA|                79.0|\n",
      "|2014-05-02 00:00:00| 588500.0|     3.0|     1.75|       2330|   14892|   1.0|         0|   0|        3|      1970|          360|    1980|           0|    1833 220th Pl NE|       Sammamish|WA 98074|    USA|             -1980.0|\n",
      "|2014-05-02 00:00:00| 365000.0|     3.0|      1.0|       1090|    6435|   1.0|         0|   0|        4|      1090|            0|    1955|        2009| 2504 SW Portland Ct|         Seattle|WA 98106|    USA|                54.0|\n",
      "|2014-05-02 00:00:00|1200000.0|     5.0|     2.75|       2910|    9480|   1.5|         0|   0|        3|      2910|            0|    1939|        1969|    3534 46th Ave NE|         Seattle|WA 98105|    USA|                30.0|\n",
      "|2014-05-02 00:00:00| 242500.0|     3.0|      1.5|       1200|    9720|   1.0|         0|   0|        4|      1200|            0|    1965|           0|   14034 SE 201st St|            Kent|WA 98042|    USA|             -1965.0|\n",
      "|2014-05-02 00:00:00| 419000.0|     3.0|      1.5|       1570|    6700|   1.0|         0|   0|        4|      1570|            0|    1956|           0|     15424 SE 9th St|        Bellevue|WA 98007|    USA|             -1956.0|\n",
      "|2014-05-02 00:00:00| 367500.0|     4.0|      3.0|       3110|    7231|   2.0|         0|   0|        3|      3110|            0|    1997|           0|   11224 SE 306th Pl|          Auburn|WA 98092|    USA|             -1997.0|\n",
      "|2014-05-02 00:00:00| 257950.0|     3.0|     1.75|       1370|    5858|   1.0|         0|   0|        3|      1370|            0|    1987|        2000|     1605 S 245th Pl|      Des Moines|WA 98198|    USA|                13.0|\n",
      "|2014-05-02 00:00:00| 275000.0|     3.0|      1.5|       1180|   10277|   1.0|         0|   0|        3|      1180|            0|    1983|        2009|  12425 415th Ave SE|      North Bend|WA 98045|    USA|                26.0|\n",
      "+-------------------+---------+--------+---------+-----------+--------+------+----------+----+---------+----------+-------------+--------+------------+--------------------+----------------+--------+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop(how='all').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+--------+---------+-----------+--------+------+----------+----+---------+----------+-------------+--------+------------+--------------------+----------------+--------+-------+--------------------+\n",
      "|               date|    price|bedrooms|bathrooms|sqft_living|sqft_lot|floors|waterfront|view|condition|sqft_above|sqft_basement|yr_built|yr_renovated|              street|            city|statezip|country|yr_before_renovation|\n",
      "+-------------------+---------+--------+---------+-----------+--------+------+----------+----+---------+----------+-------------+--------+------------+--------------------+----------------+--------+-------+--------------------+\n",
      "|2014-05-02 00:00:00| 313000.0|     3.0|      1.5|       1340|    7912|   1.5|         0|   0|        3|      1340|            0|    1955|        2005|18810 Densmore Ave N|       Shoreline|WA 98133|    USA|                50.0|\n",
      "|2014-05-02 00:00:00|2384000.0|     5.0|      2.5|       3650|    9050|   2.0|         0|   4|        5|      3370|          280|    1921|           0|     709 W Blaine St|         Seattle|WA 98119|    USA|             -1921.0|\n",
      "|2014-05-02 00:00:00| 342000.0|     3.0|      2.0|       1930|   11947|   1.0|         0|   0|        4|      1930|            0|    1966|           0|26206-26214 143rd...|            Kent|WA 98042|    USA|             -1966.0|\n",
      "|2014-05-02 00:00:00| 420000.0|     3.0|     2.25|       2000|    8030|   1.0|         0|   0|        4|      1000|         1000|    1963|           0|     857 170th Pl NE|        Bellevue|WA 98008|    USA|             -1963.0|\n",
      "|2014-05-02 00:00:00| 550000.0|     4.0|      2.5|       1940|   10500|   1.0|         0|   0|        4|      1140|          800|    1976|        1992|   9105 170th Ave NE|         Redmond|WA 98052|    USA|                16.0|\n",
      "|2014-05-02 00:00:00| 490000.0|     2.0|      1.0|        880|    6380|   1.0|         0|   0|        3|       880|            0|    1938|        1994|      522 NE 88th St|         Seattle|WA 98115|    USA|                56.0|\n",
      "|2014-05-02 00:00:00| 335000.0|     2.0|      2.0|       1350|    2560|   1.0|         0|   0|        3|      1350|            0|    1976|           0|   2616 174th Ave NE|         Redmond|WA 98052|    USA|             -1976.0|\n",
      "|2014-05-02 00:00:00| 482000.0|     4.0|      2.5|       2710|   35868|   2.0|         0|   0|        3|      2710|            0|    1989|           0|   23762 SE 253rd Pl|    Maple Valley|WA 98038|    USA|             -1989.0|\n",
      "|2014-05-02 00:00:00| 452500.0|     3.0|      2.5|       2430|   88426|   1.0|         0|   0|        4|      1570|          860|    1985|           0|46611-46625 SE 12...|      North Bend|WA 98045|    USA|             -1985.0|\n",
      "|2014-05-02 00:00:00| 640000.0|     4.0|      2.0|       1520|    6200|   1.5|         0|   0|        3|      1520|            0|    1945|        2010|    6811 55th Ave NE|         Seattle|WA 98115|    USA|                65.0|\n",
      "|2014-05-02 00:00:00| 463000.0|     3.0|     1.75|       1710|    7320|   1.0|         0|   0|        3|      1710|            0|    1948|        1994|  Burke-Gilman Trail|Lake Forest Park|WA 98155|    USA|                46.0|\n",
      "|2014-05-02 00:00:00|1400000.0|     4.0|      2.5|       2920|    4000|   1.5|         0|   0|        5|      1910|         1010|    1909|        1988|3838-4098 44th Av...|         Seattle|WA 98105|    USA|                79.0|\n",
      "|2014-05-02 00:00:00| 588500.0|     3.0|     1.75|       2330|   14892|   1.0|         0|   0|        3|      1970|          360|    1980|           0|    1833 220th Pl NE|       Sammamish|WA 98074|    USA|             -1980.0|\n",
      "|2014-05-02 00:00:00| 365000.0|     3.0|      1.0|       1090|    6435|   1.0|         0|   0|        4|      1090|            0|    1955|        2009| 2504 SW Portland Ct|         Seattle|WA 98106|    USA|                54.0|\n",
      "|2014-05-02 00:00:00|1200000.0|     5.0|     2.75|       2910|    9480|   1.5|         0|   0|        3|      2910|            0|    1939|        1969|    3534 46th Ave NE|         Seattle|WA 98105|    USA|                30.0|\n",
      "|2014-05-02 00:00:00| 242500.0|     3.0|      1.5|       1200|    9720|   1.0|         0|   0|        4|      1200|            0|    1965|           0|   14034 SE 201st St|            Kent|WA 98042|    USA|             -1965.0|\n",
      "|2014-05-02 00:00:00| 419000.0|     3.0|      1.5|       1570|    6700|   1.0|         0|   0|        4|      1570|            0|    1956|           0|     15424 SE 9th St|        Bellevue|WA 98007|    USA|             -1956.0|\n",
      "|2014-05-02 00:00:00| 367500.0|     4.0|      3.0|       3110|    7231|   2.0|         0|   0|        3|      3110|            0|    1997|           0|   11224 SE 306th Pl|          Auburn|WA 98092|    USA|             -1997.0|\n",
      "|2014-05-02 00:00:00| 257950.0|     3.0|     1.75|       1370|    5858|   1.0|         0|   0|        3|      1370|            0|    1987|        2000|     1605 S 245th Pl|      Des Moines|WA 98198|    USA|                13.0|\n",
      "|2014-05-02 00:00:00| 275000.0|     3.0|      1.5|       1180|   10277|   1.0|         0|   0|        3|      1180|            0|    1983|        2009|  12425 415th Ave SE|      North Bend|WA 98045|    USA|                26.0|\n",
      "+-------------------+---------+--------+---------+-----------+--------+------+----------+----+---------+----------+-------------+--------+------------+--------------------+----------------+--------+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df.na.drop(how='any').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+--------+---------+-----------+--------+------+----------+----+---------+----------+-------------+--------+------------+--------------------+----------------+--------+-------+--------------------+\n",
      "|               date|    price|bedrooms|bathrooms|sqft_living|sqft_lot|floors|waterfront|view|condition|sqft_above|sqft_basement|yr_built|yr_renovated|              street|            city|statezip|country|yr_before_renovation|\n",
      "+-------------------+---------+--------+---------+-----------+--------+------+----------+----+---------+----------+-------------+--------+------------+--------------------+----------------+--------+-------+--------------------+\n",
      "|2014-05-02 00:00:00| 313000.0|     3.0|      1.5|       1340|    7912|   1.5|         0|   0|        3|      1340|            0|    1955|        2005|18810 Densmore Ave N|       Shoreline|WA 98133|    USA|                50.0|\n",
      "|2014-05-02 00:00:00|2384000.0|     5.0|      2.5|       3650|    9050|   2.0|         0|   4|        5|      3370|          280|    1921|           0|     709 W Blaine St|         Seattle|WA 98119|    USA|             -1921.0|\n",
      "|2014-05-02 00:00:00| 342000.0|     3.0|      2.0|       1930|   11947|   1.0|         0|   0|        4|      1930|            0|    1966|           0|26206-26214 143rd...|            Kent|WA 98042|    USA|             -1966.0|\n",
      "|2014-05-02 00:00:00| 420000.0|     3.0|     2.25|       2000|    8030|   1.0|         0|   0|        4|      1000|         1000|    1963|           0|     857 170th Pl NE|        Bellevue|WA 98008|    USA|             -1963.0|\n",
      "|2014-05-02 00:00:00| 550000.0|     4.0|      2.5|       1940|   10500|   1.0|         0|   0|        4|      1140|          800|    1976|        1992|   9105 170th Ave NE|         Redmond|WA 98052|    USA|                16.0|\n",
      "|2014-05-02 00:00:00| 490000.0|     2.0|      1.0|        880|    6380|   1.0|         0|   0|        3|       880|            0|    1938|        1994|      522 NE 88th St|         Seattle|WA 98115|    USA|                56.0|\n",
      "|2014-05-02 00:00:00| 335000.0|     2.0|      2.0|       1350|    2560|   1.0|         0|   0|        3|      1350|            0|    1976|           0|   2616 174th Ave NE|         Redmond|WA 98052|    USA|             -1976.0|\n",
      "|2014-05-02 00:00:00| 482000.0|     4.0|      2.5|       2710|   35868|   2.0|         0|   0|        3|      2710|            0|    1989|           0|   23762 SE 253rd Pl|    Maple Valley|WA 98038|    USA|             -1989.0|\n",
      "|2014-05-02 00:00:00| 452500.0|     3.0|      2.5|       2430|   88426|   1.0|         0|   0|        4|      1570|          860|    1985|           0|46611-46625 SE 12...|      North Bend|WA 98045|    USA|             -1985.0|\n",
      "|2014-05-02 00:00:00| 640000.0|     4.0|      2.0|       1520|    6200|   1.5|         0|   0|        3|      1520|            0|    1945|        2010|    6811 55th Ave NE|         Seattle|WA 98115|    USA|                65.0|\n",
      "|2014-05-02 00:00:00| 463000.0|     3.0|     1.75|       1710|    7320|   1.0|         0|   0|        3|      1710|            0|    1948|        1994|  Burke-Gilman Trail|Lake Forest Park|WA 98155|    USA|                46.0|\n",
      "|2014-05-02 00:00:00|1400000.0|     4.0|      2.5|       2920|    4000|   1.5|         0|   0|        5|      1910|         1010|    1909|        1988|3838-4098 44th Av...|         Seattle|WA 98105|    USA|                79.0|\n",
      "|2014-05-02 00:00:00| 588500.0|     3.0|     1.75|       2330|   14892|   1.0|         0|   0|        3|      1970|          360|    1980|           0|    1833 220th Pl NE|       Sammamish|WA 98074|    USA|             -1980.0|\n",
      "|2014-05-02 00:00:00| 365000.0|     3.0|      1.0|       1090|    6435|   1.0|         0|   0|        4|      1090|            0|    1955|        2009| 2504 SW Portland Ct|         Seattle|WA 98106|    USA|                54.0|\n",
      "|2014-05-02 00:00:00|1200000.0|     5.0|     2.75|       2910|    9480|   1.5|         0|   0|        3|      2910|            0|    1939|        1969|    3534 46th Ave NE|         Seattle|WA 98105|    USA|                30.0|\n",
      "|2014-05-02 00:00:00| 242500.0|     3.0|      1.5|       1200|    9720|   1.0|         0|   0|        4|      1200|            0|    1965|           0|   14034 SE 201st St|            Kent|WA 98042|    USA|             -1965.0|\n",
      "|2014-05-02 00:00:00| 419000.0|     3.0|      1.5|       1570|    6700|   1.0|         0|   0|        4|      1570|            0|    1956|           0|     15424 SE 9th St|        Bellevue|WA 98007|    USA|             -1956.0|\n",
      "|2014-05-02 00:00:00| 367500.0|     4.0|      3.0|       3110|    7231|   2.0|         0|   0|        3|      3110|            0|    1997|           0|   11224 SE 306th Pl|          Auburn|WA 98092|    USA|             -1997.0|\n",
      "|2014-05-02 00:00:00| 257950.0|     3.0|     1.75|       1370|    5858|   1.0|         0|   0|        3|      1370|            0|    1987|        2000|     1605 S 245th Pl|      Des Moines|WA 98198|    USA|                13.0|\n",
      "|2014-05-02 00:00:00| 275000.0|     3.0|      1.5|       1180|   10277|   1.0|         0|   0|        3|      1180|            0|    1983|        2009|  12425 415th Ave SE|      North Bend|WA 98045|    USA|                26.0|\n",
      "+-------------------+---------+--------+---------+-----------+--------+------+----------+----+---------+----------+-------------+--------+------------+--------------------+----------------+--------+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop(subset=['price']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+--------+---------+-----------+--------+------+----------+----+---------+----------+-------------+--------+------------+--------------------+----------------+--------+-------+--------------------+\n",
      "|               date|    price|bedrooms|bathrooms|sqft_living|sqft_lot|floors|waterfront|view|condition|sqft_above|sqft_basement|yr_built|yr_renovated|              street|            city|statezip|country|yr_before_renovation|\n",
      "+-------------------+---------+--------+---------+-----------+--------+------+----------+----+---------+----------+-------------+--------+------------+--------------------+----------------+--------+-------+--------------------+\n",
      "|2014-05-02 00:00:00| 313000.0|     3.0|      1.5|       1340|    7912|   1.5|         0|   0|        3|      1340|            0|    1955|        2005|18810 Densmore Ave N|       Shoreline|WA 98133|    USA|                50.0|\n",
      "|2014-05-02 00:00:00|2384000.0|     5.0|      2.5|       3650|    9050|   2.0|         0|   4|        5|      3370|          280|    1921|           0|     709 W Blaine St|         Seattle|WA 98119|    USA|             -1921.0|\n",
      "|2014-05-02 00:00:00| 342000.0|     3.0|      2.0|       1930|   11947|   1.0|         0|   0|        4|      1930|            0|    1966|           0|26206-26214 143rd...|            Kent|WA 98042|    USA|             -1966.0|\n",
      "|2014-05-02 00:00:00| 420000.0|     3.0|     2.25|       2000|    8030|   1.0|         0|   0|        4|      1000|         1000|    1963|           0|     857 170th Pl NE|        Bellevue|WA 98008|    USA|             -1963.0|\n",
      "|2014-05-02 00:00:00| 550000.0|     4.0|      2.5|       1940|   10500|   1.0|         0|   0|        4|      1140|          800|    1976|        1992|   9105 170th Ave NE|         Redmond|WA 98052|    USA|                16.0|\n",
      "|2014-05-02 00:00:00| 490000.0|     2.0|      1.0|        880|    6380|   1.0|         0|   0|        3|       880|            0|    1938|        1994|      522 NE 88th St|         Seattle|WA 98115|    USA|                56.0|\n",
      "|2014-05-02 00:00:00| 335000.0|     2.0|      2.0|       1350|    2560|   1.0|         0|   0|        3|      1350|            0|    1976|           0|   2616 174th Ave NE|         Redmond|WA 98052|    USA|             -1976.0|\n",
      "|2014-05-02 00:00:00| 482000.0|     4.0|      2.5|       2710|   35868|   2.0|         0|   0|        3|      2710|            0|    1989|           0|   23762 SE 253rd Pl|    Maple Valley|WA 98038|    USA|             -1989.0|\n",
      "|2014-05-02 00:00:00| 452500.0|     3.0|      2.5|       2430|   88426|   1.0|         0|   0|        4|      1570|          860|    1985|           0|46611-46625 SE 12...|      North Bend|WA 98045|    USA|             -1985.0|\n",
      "|2014-05-02 00:00:00| 640000.0|     4.0|      2.0|       1520|    6200|   1.5|         0|   0|        3|      1520|            0|    1945|        2010|    6811 55th Ave NE|         Seattle|WA 98115|    USA|                65.0|\n",
      "|2014-05-02 00:00:00| 463000.0|     3.0|     1.75|       1710|    7320|   1.0|         0|   0|        3|      1710|            0|    1948|        1994|  Burke-Gilman Trail|Lake Forest Park|WA 98155|    USA|                46.0|\n",
      "|2014-05-02 00:00:00|1400000.0|     4.0|      2.5|       2920|    4000|   1.5|         0|   0|        5|      1910|         1010|    1909|        1988|3838-4098 44th Av...|         Seattle|WA 98105|    USA|                79.0|\n",
      "|2014-05-02 00:00:00| 588500.0|     3.0|     1.75|       2330|   14892|   1.0|         0|   0|        3|      1970|          360|    1980|           0|    1833 220th Pl NE|       Sammamish|WA 98074|    USA|             -1980.0|\n",
      "|2014-05-02 00:00:00| 365000.0|     3.0|      1.0|       1090|    6435|   1.0|         0|   0|        4|      1090|            0|    1955|        2009| 2504 SW Portland Ct|         Seattle|WA 98106|    USA|                54.0|\n",
      "|2014-05-02 00:00:00|1200000.0|     5.0|     2.75|       2910|    9480|   1.5|         0|   0|        3|      2910|            0|    1939|        1969|    3534 46th Ave NE|         Seattle|WA 98105|    USA|                30.0|\n",
      "|2014-05-02 00:00:00| 242500.0|     3.0|      1.5|       1200|    9720|   1.0|         0|   0|        4|      1200|            0|    1965|           0|   14034 SE 201st St|            Kent|WA 98042|    USA|             -1965.0|\n",
      "|2014-05-02 00:00:00| 419000.0|     3.0|      1.5|       1570|    6700|   1.0|         0|   0|        4|      1570|            0|    1956|           0|     15424 SE 9th St|        Bellevue|WA 98007|    USA|             -1956.0|\n",
      "|2014-05-02 00:00:00| 367500.0|     4.0|      3.0|       3110|    7231|   2.0|         0|   0|        3|      3110|            0|    1997|           0|   11224 SE 306th Pl|          Auburn|WA 98092|    USA|             -1997.0|\n",
      "|2014-05-02 00:00:00| 257950.0|     3.0|     1.75|       1370|    5858|   1.0|         0|   0|        3|      1370|            0|    1987|        2000|     1605 S 245th Pl|      Des Moines|WA 98198|    USA|                13.0|\n",
      "|2014-05-02 00:00:00| 275000.0|     3.0|      1.5|       1180|   10277|   1.0|         0|   0|        3|      1180|            0|    1983|        2009|  12425 415th Ave SE|      North Bend|WA 98045|    USA|                26.0|\n",
      "+-------------------+---------+--------+---------+-----------+--------+------+----------+----+---------+----------+-------------+--------+------------+--------------------+----------------+--------+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.fill('VALUE').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+--------+---------+-----------+--------+------+----------+----+---------+----------+-------------+--------+------------+--------------------+----------------+--------+-------+--------------------+\n",
      "|               date|    price|bedrooms|bathrooms|sqft_living|sqft_lot|floors|waterfront|view|condition|sqft_above|sqft_basement|yr_built|yr_renovated|              street|            city|statezip|country|yr_before_renovation|\n",
      "+-------------------+---------+--------+---------+-----------+--------+------+----------+----+---------+----------+-------------+--------+------------+--------------------+----------------+--------+-------+--------------------+\n",
      "|2014-05-02 00:00:00| 313000.0|     3.0|      1.5|       1340|    7912|   1.5|         0|   0|        3|      1340|            0|    1955|        2005|18810 Densmore Ave N|       Shoreline|WA 98133|    USA|                50.0|\n",
      "|2014-05-02 00:00:00|2384000.0|     5.0|      2.5|       3650|    9050|   2.0|         0|   4|        5|      3370|          280|    1921|           0|     709 W Blaine St|         Seattle|WA 98119|    USA|             -1921.0|\n",
      "|2014-05-02 00:00:00| 342000.0|     3.0|      2.0|       1930|   11947|   1.0|         0|   0|        4|      1930|            0|    1966|           0|26206-26214 143rd...|            Kent|WA 98042|    USA|             -1966.0|\n",
      "|2014-05-02 00:00:00| 420000.0|     3.0|     2.25|       2000|    8030|   1.0|         0|   0|        4|      1000|         1000|    1963|           0|     857 170th Pl NE|        Bellevue|WA 98008|    USA|             -1963.0|\n",
      "|2014-05-02 00:00:00| 550000.0|     4.0|      2.5|       1940|   10500|   1.0|         0|   0|        4|      1140|          800|    1976|        1992|   9105 170th Ave NE|         Redmond|WA 98052|    USA|                16.0|\n",
      "|2014-05-02 00:00:00| 490000.0|     2.0|      1.0|        880|    6380|   1.0|         0|   0|        3|       880|            0|    1938|        1994|      522 NE 88th St|         Seattle|WA 98115|    USA|                56.0|\n",
      "|2014-05-02 00:00:00| 335000.0|     2.0|      2.0|       1350|    2560|   1.0|         0|   0|        3|      1350|            0|    1976|           0|   2616 174th Ave NE|         Redmond|WA 98052|    USA|             -1976.0|\n",
      "|2014-05-02 00:00:00| 482000.0|     4.0|      2.5|       2710|   35868|   2.0|         0|   0|        3|      2710|            0|    1989|           0|   23762 SE 253rd Pl|    Maple Valley|WA 98038|    USA|             -1989.0|\n",
      "|2014-05-02 00:00:00| 452500.0|     3.0|      2.5|       2430|   88426|   1.0|         0|   0|        4|      1570|          860|    1985|           0|46611-46625 SE 12...|      North Bend|WA 98045|    USA|             -1985.0|\n",
      "|2014-05-02 00:00:00| 640000.0|     4.0|      2.0|       1520|    6200|   1.5|         0|   0|        3|      1520|            0|    1945|        2010|    6811 55th Ave NE|         Seattle|WA 98115|    USA|                65.0|\n",
      "|2014-05-02 00:00:00| 463000.0|     3.0|     1.75|       1710|    7320|   1.0|         0|   0|        3|      1710|            0|    1948|        1994|  Burke-Gilman Trail|Lake Forest Park|WA 98155|    USA|                46.0|\n",
      "|2014-05-02 00:00:00|1400000.0|     4.0|      2.5|       2920|    4000|   1.5|         0|   0|        5|      1910|         1010|    1909|        1988|3838-4098 44th Av...|         Seattle|WA 98105|    USA|                79.0|\n",
      "|2014-05-02 00:00:00| 588500.0|     3.0|     1.75|       2330|   14892|   1.0|         0|   0|        3|      1970|          360|    1980|           0|    1833 220th Pl NE|       Sammamish|WA 98074|    USA|             -1980.0|\n",
      "|2014-05-02 00:00:00| 365000.0|     3.0|      1.0|       1090|    6435|   1.0|         0|   0|        4|      1090|            0|    1955|        2009| 2504 SW Portland Ct|         Seattle|WA 98106|    USA|                54.0|\n",
      "|2014-05-02 00:00:00|1200000.0|     5.0|     2.75|       2910|    9480|   1.5|         0|   0|        3|      2910|            0|    1939|        1969|    3534 46th Ave NE|         Seattle|WA 98105|    USA|                30.0|\n",
      "|2014-05-02 00:00:00| 242500.0|     3.0|      1.5|       1200|    9720|   1.0|         0|   0|        4|      1200|            0|    1965|           0|   14034 SE 201st St|            Kent|WA 98042|    USA|             -1965.0|\n",
      "|2014-05-02 00:00:00| 419000.0|     3.0|      1.5|       1570|    6700|   1.0|         0|   0|        4|      1570|            0|    1956|           0|     15424 SE 9th St|        Bellevue|WA 98007|    USA|             -1956.0|\n",
      "|2014-05-02 00:00:00| 367500.0|     4.0|      3.0|       3110|    7231|   2.0|         0|   0|        3|      3110|            0|    1997|           0|   11224 SE 306th Pl|          Auburn|WA 98092|    USA|             -1997.0|\n",
      "|2014-05-02 00:00:00| 257950.0|     3.0|     1.75|       1370|    5858|   1.0|         0|   0|        3|      1370|            0|    1987|        2000|     1605 S 245th Pl|      Des Moines|WA 98198|    USA|                13.0|\n",
      "|2014-05-02 00:00:00| 275000.0|     3.0|      1.5|       1180|   10277|   1.0|         0|   0|        3|      1180|            0|    1983|        2009|  12425 415th Ave SE|      North Bend|WA 98045|    USA|                26.0|\n",
      "+-------------------+---------+--------+---------+-----------+--------+------+----------+----+---------+----------+-------------+--------+------------+--------------------+----------------+--------+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.fill('city not found', subset=['city']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dates and Timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(date='2014-05-02 00:00:00', price='313000.0', bedrooms='3.0', bathrooms='1.5', sqft_living='1340', sqft_lot='7912', floors='1.5', waterfront='0', view='0', condition='3', sqft_above='1340', sqft_basement='0', yr_built='1955', yr_renovated='2005', street='18810 Densmore Ave N', city='Shoreline', statezip='WA 98133', country='USA', yr_before_renovation=50.0)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+\n",
      "|               date|    price|\n",
      "+-------------------+---------+\n",
      "|2014-05-02 00:00:00| 313000.0|\n",
      "|2014-05-02 00:00:00|2384000.0|\n",
      "|2014-05-02 00:00:00| 342000.0|\n",
      "|2014-05-02 00:00:00| 420000.0|\n",
      "|2014-05-02 00:00:00| 550000.0|\n",
      "|2014-05-02 00:00:00| 490000.0|\n",
      "|2014-05-02 00:00:00| 335000.0|\n",
      "|2014-05-02 00:00:00| 482000.0|\n",
      "|2014-05-02 00:00:00| 452500.0|\n",
      "|2014-05-02 00:00:00| 640000.0|\n",
      "|2014-05-02 00:00:00| 463000.0|\n",
      "|2014-05-02 00:00:00|1400000.0|\n",
      "|2014-05-02 00:00:00| 588500.0|\n",
      "|2014-05-02 00:00:00| 365000.0|\n",
      "|2014-05-02 00:00:00|1200000.0|\n",
      "|2014-05-02 00:00:00| 242500.0|\n",
      "|2014-05-02 00:00:00| 419000.0|\n",
      "|2014-05-02 00:00:00| 367500.0|\n",
      "|2014-05-02 00:00:00| 257950.0|\n",
      "|2014-05-02 00:00:00| 275000.0|\n",
      "+-------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(['date', 'price']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import dayofmonth, hour, dayofyear, month, year, weekofyear, format_number, date_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|dayofmonth(date)|\n",
      "+----------------+\n",
      "|               2|\n",
      "|               2|\n",
      "|               2|\n",
      "|               2|\n",
      "|               2|\n",
      "|               2|\n",
      "|               2|\n",
      "|               2|\n",
      "|               2|\n",
      "|               2|\n",
      "|               2|\n",
      "|               2|\n",
      "|               2|\n",
      "|               2|\n",
      "|               2|\n",
      "|               2|\n",
      "|               2|\n",
      "|               2|\n",
      "|               2|\n",
      "|               2|\n",
      "+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# you can directly use anyimported funvtions from the select on your column\n",
    "df.select(dayofmonth(df['date'])).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|month(date)|\n",
      "+-----------+\n",
      "|          5|\n",
      "|          5|\n",
      "|          5|\n",
      "|          5|\n",
      "|          5|\n",
      "|          5|\n",
      "|          5|\n",
      "|          5|\n",
      "|          5|\n",
      "|          5|\n",
      "|          5|\n",
      "|          5|\n",
      "|          5|\n",
      "|          5|\n",
      "|          5|\n",
      "|          5|\n",
      "|          5|\n",
      "|          5|\n",
      "|          5|\n",
      "|          5|\n",
      "+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(month(df['date'])).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+--------+---------+-----------+--------+------+----------+----+---------+----------+-------------+--------+------------+--------------------+----------------+--------+-------+--------------------+----+\n",
      "|               date|    price|bedrooms|bathrooms|sqft_living|sqft_lot|floors|waterfront|view|condition|sqft_above|sqft_basement|yr_built|yr_renovated|              street|            city|statezip|country|yr_before_renovation|Year|\n",
      "+-------------------+---------+--------+---------+-----------+--------+------+----------+----+---------+----------+-------------+--------+------------+--------------------+----------------+--------+-------+--------------------+----+\n",
      "|2014-05-02 00:00:00| 313000.0|     3.0|      1.5|       1340|    7912|   1.5|         0|   0|        3|      1340|            0|    1955|        2005|18810 Densmore Ave N|       Shoreline|WA 98133|    USA|                50.0|2014|\n",
      "|2014-05-02 00:00:00|2384000.0|     5.0|      2.5|       3650|    9050|   2.0|         0|   4|        5|      3370|          280|    1921|           0|     709 W Blaine St|         Seattle|WA 98119|    USA|             -1921.0|2014|\n",
      "|2014-05-02 00:00:00| 342000.0|     3.0|      2.0|       1930|   11947|   1.0|         0|   0|        4|      1930|            0|    1966|           0|26206-26214 143rd...|            Kent|WA 98042|    USA|             -1966.0|2014|\n",
      "|2014-05-02 00:00:00| 420000.0|     3.0|     2.25|       2000|    8030|   1.0|         0|   0|        4|      1000|         1000|    1963|           0|     857 170th Pl NE|        Bellevue|WA 98008|    USA|             -1963.0|2014|\n",
      "|2014-05-02 00:00:00| 550000.0|     4.0|      2.5|       1940|   10500|   1.0|         0|   0|        4|      1140|          800|    1976|        1992|   9105 170th Ave NE|         Redmond|WA 98052|    USA|                16.0|2014|\n",
      "|2014-05-02 00:00:00| 490000.0|     2.0|      1.0|        880|    6380|   1.0|         0|   0|        3|       880|            0|    1938|        1994|      522 NE 88th St|         Seattle|WA 98115|    USA|                56.0|2014|\n",
      "|2014-05-02 00:00:00| 335000.0|     2.0|      2.0|       1350|    2560|   1.0|         0|   0|        3|      1350|            0|    1976|           0|   2616 174th Ave NE|         Redmond|WA 98052|    USA|             -1976.0|2014|\n",
      "|2014-05-02 00:00:00| 482000.0|     4.0|      2.5|       2710|   35868|   2.0|         0|   0|        3|      2710|            0|    1989|           0|   23762 SE 253rd Pl|    Maple Valley|WA 98038|    USA|             -1989.0|2014|\n",
      "|2014-05-02 00:00:00| 452500.0|     3.0|      2.5|       2430|   88426|   1.0|         0|   0|        4|      1570|          860|    1985|           0|46611-46625 SE 12...|      North Bend|WA 98045|    USA|             -1985.0|2014|\n",
      "|2014-05-02 00:00:00| 640000.0|     4.0|      2.0|       1520|    6200|   1.5|         0|   0|        3|      1520|            0|    1945|        2010|    6811 55th Ave NE|         Seattle|WA 98115|    USA|                65.0|2014|\n",
      "|2014-05-02 00:00:00| 463000.0|     3.0|     1.75|       1710|    7320|   1.0|         0|   0|        3|      1710|            0|    1948|        1994|  Burke-Gilman Trail|Lake Forest Park|WA 98155|    USA|                46.0|2014|\n",
      "|2014-05-02 00:00:00|1400000.0|     4.0|      2.5|       2920|    4000|   1.5|         0|   0|        5|      1910|         1010|    1909|        1988|3838-4098 44th Av...|         Seattle|WA 98105|    USA|                79.0|2014|\n",
      "|2014-05-02 00:00:00| 588500.0|     3.0|     1.75|       2330|   14892|   1.0|         0|   0|        3|      1970|          360|    1980|           0|    1833 220th Pl NE|       Sammamish|WA 98074|    USA|             -1980.0|2014|\n",
      "|2014-05-02 00:00:00| 365000.0|     3.0|      1.0|       1090|    6435|   1.0|         0|   0|        4|      1090|            0|    1955|        2009| 2504 SW Portland Ct|         Seattle|WA 98106|    USA|                54.0|2014|\n",
      "|2014-05-02 00:00:00|1200000.0|     5.0|     2.75|       2910|    9480|   1.5|         0|   0|        3|      2910|            0|    1939|        1969|    3534 46th Ave NE|         Seattle|WA 98105|    USA|                30.0|2014|\n",
      "|2014-05-02 00:00:00| 242500.0|     3.0|      1.5|       1200|    9720|   1.0|         0|   0|        4|      1200|            0|    1965|           0|   14034 SE 201st St|            Kent|WA 98042|    USA|             -1965.0|2014|\n",
      "|2014-05-02 00:00:00| 419000.0|     3.0|      1.5|       1570|    6700|   1.0|         0|   0|        4|      1570|            0|    1956|           0|     15424 SE 9th St|        Bellevue|WA 98007|    USA|             -1956.0|2014|\n",
      "|2014-05-02 00:00:00| 367500.0|     4.0|      3.0|       3110|    7231|   2.0|         0|   0|        3|      3110|            0|    1997|           0|   11224 SE 306th Pl|          Auburn|WA 98092|    USA|             -1997.0|2014|\n",
      "|2014-05-02 00:00:00| 257950.0|     3.0|     1.75|       1370|    5858|   1.0|         0|   0|        3|      1370|            0|    1987|        2000|     1605 S 245th Pl|      Des Moines|WA 98198|    USA|                13.0|2014|\n",
      "|2014-05-02 00:00:00| 275000.0|     3.0|      1.5|       1180|   10277|   1.0|         0|   0|        3|      1180|            0|    1983|        2009|  12425 415th Ave SE|      North Bend|WA 98045|    USA|                26.0|2014|\n",
      "+-------------------+---------+--------+---------+-----------+--------+------+----------+----+---------+----------+-------------+--------+------------+--------------------+----------------+--------+-------+--------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn('Year', year(df.date)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+----+\n",
      "|month|weekofyear|year|\n",
      "+-----+----------+----+\n",
      "|    5|        18|2014|\n",
      "|    5|        18|2014|\n",
      "|    5|        18|2014|\n",
      "|    5|        18|2014|\n",
      "|    5|        18|2014|\n",
      "|    5|        18|2014|\n",
      "|    5|        18|2014|\n",
      "|    5|        18|2014|\n",
      "|    5|        18|2014|\n",
      "|    5|        18|2014|\n",
      "|    5|        18|2014|\n",
      "|    5|        18|2014|\n",
      "|    5|        18|2014|\n",
      "|    5|        18|2014|\n",
      "|    5|        18|2014|\n",
      "|    5|        18|2014|\n",
      "|    5|        18|2014|\n",
      "|    5|        18|2014|\n",
      "|    5|        18|2014|\n",
      "|    5|        18|2014|\n",
      "+-----+----------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn('month', month(df.date))\n",
    "df = df.withColumn('weekofyear', weekofyear(df.date))\n",
    "df = df.withColumn('year', year(df.date))\n",
    "\n",
    "df.select(['month', 'weekofyear', 'year']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------------+------------------+-----------------+---------+\n",
      "|year|avg(yr_before_renovation)|        avg(month)|  avg(weekofyear)|avg(year)|\n",
      "+----+-------------------------+------------------+-----------------+---------+\n",
      "|2014|      -1162.1780434782609|5.7576086956521735|23.44717391304348|   2014.0|\n",
      "+----+-------------------------+------------------+-----------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('year').mean().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+--------+---------+-----------+--------+------+----------+----+---------+----------+-------------+--------+------------+--------------------+----------------+--------+-------+--------------------+-----+----------+----+\n",
      "|               date|    price|bedrooms|bathrooms|sqft_living|sqft_lot|floors|waterfront|view|condition|sqft_above|sqft_basement|yr_built|yr_renovated|              street|            city|statezip|country|yr_before_renovation|month|weekofyear|year|\n",
      "+-------------------+---------+--------+---------+-----------+--------+------+----------+----+---------+----------+-------------+--------+------------+--------------------+----------------+--------+-------+--------------------+-----+----------+----+\n",
      "|2014-05-02 00:00:00| 313000.0|     3.0|      1.5|       1340|    7912|   1.5|         0|   0|        3|      1340|            0|    1955|        2005|18810 Densmore Ave N|       Shoreline|WA 98133|    USA|                50.0|    5|        18|2014|\n",
      "|2014-05-02 00:00:00|2384000.0|     5.0|      2.5|       3650|    9050|   2.0|         0|   4|        5|      3370|          280|    1921|           0|     709 W Blaine St|         Seattle|WA 98119|    USA|             -1921.0|    5|        18|2014|\n",
      "|2014-05-02 00:00:00| 342000.0|     3.0|      2.0|       1930|   11947|   1.0|         0|   0|        4|      1930|            0|    1966|           0|26206-26214 143rd...|            Kent|WA 98042|    USA|             -1966.0|    5|        18|2014|\n",
      "|2014-05-02 00:00:00| 420000.0|     3.0|     2.25|       2000|    8030|   1.0|         0|   0|        4|      1000|         1000|    1963|           0|     857 170th Pl NE|        Bellevue|WA 98008|    USA|             -1963.0|    5|        18|2014|\n",
      "|2014-05-02 00:00:00| 550000.0|     4.0|      2.5|       1940|   10500|   1.0|         0|   0|        4|      1140|          800|    1976|        1992|   9105 170th Ave NE|         Redmond|WA 98052|    USA|                16.0|    5|        18|2014|\n",
      "|2014-05-02 00:00:00| 490000.0|     2.0|      1.0|        880|    6380|   1.0|         0|   0|        3|       880|            0|    1938|        1994|      522 NE 88th St|         Seattle|WA 98115|    USA|                56.0|    5|        18|2014|\n",
      "|2014-05-02 00:00:00| 335000.0|     2.0|      2.0|       1350|    2560|   1.0|         0|   0|        3|      1350|            0|    1976|           0|   2616 174th Ave NE|         Redmond|WA 98052|    USA|             -1976.0|    5|        18|2014|\n",
      "|2014-05-02 00:00:00| 482000.0|     4.0|      2.5|       2710|   35868|   2.0|         0|   0|        3|      2710|            0|    1989|           0|   23762 SE 253rd Pl|    Maple Valley|WA 98038|    USA|             -1989.0|    5|        18|2014|\n",
      "|2014-05-02 00:00:00| 452500.0|     3.0|      2.5|       2430|   88426|   1.0|         0|   0|        4|      1570|          860|    1985|           0|46611-46625 SE 12...|      North Bend|WA 98045|    USA|             -1985.0|    5|        18|2014|\n",
      "|2014-05-02 00:00:00| 640000.0|     4.0|      2.0|       1520|    6200|   1.5|         0|   0|        3|      1520|            0|    1945|        2010|    6811 55th Ave NE|         Seattle|WA 98115|    USA|                65.0|    5|        18|2014|\n",
      "|2014-05-02 00:00:00| 463000.0|     3.0|     1.75|       1710|    7320|   1.0|         0|   0|        3|      1710|            0|    1948|        1994|  Burke-Gilman Trail|Lake Forest Park|WA 98155|    USA|                46.0|    5|        18|2014|\n",
      "|2014-05-02 00:00:00|1400000.0|     4.0|      2.5|       2920|    4000|   1.5|         0|   0|        5|      1910|         1010|    1909|        1988|3838-4098 44th Av...|         Seattle|WA 98105|    USA|                79.0|    5|        18|2014|\n",
      "|2014-05-02 00:00:00| 588500.0|     3.0|     1.75|       2330|   14892|   1.0|         0|   0|        3|      1970|          360|    1980|           0|    1833 220th Pl NE|       Sammamish|WA 98074|    USA|             -1980.0|    5|        18|2014|\n",
      "|2014-05-02 00:00:00| 365000.0|     3.0|      1.0|       1090|    6435|   1.0|         0|   0|        4|      1090|            0|    1955|        2009| 2504 SW Portland Ct|         Seattle|WA 98106|    USA|                54.0|    5|        18|2014|\n",
      "|2014-05-02 00:00:00|1200000.0|     5.0|     2.75|       2910|    9480|   1.5|         0|   0|        3|      2910|            0|    1939|        1969|    3534 46th Ave NE|         Seattle|WA 98105|    USA|                30.0|    5|        18|2014|\n",
      "|2014-05-02 00:00:00| 242500.0|     3.0|      1.5|       1200|    9720|   1.0|         0|   0|        4|      1200|            0|    1965|           0|   14034 SE 201st St|            Kent|WA 98042|    USA|             -1965.0|    5|        18|2014|\n",
      "|2014-05-02 00:00:00| 419000.0|     3.0|      1.5|       1570|    6700|   1.0|         0|   0|        4|      1570|            0|    1956|           0|     15424 SE 9th St|        Bellevue|WA 98007|    USA|             -1956.0|    5|        18|2014|\n",
      "|2014-05-02 00:00:00| 367500.0|     4.0|      3.0|       3110|    7231|   2.0|         0|   0|        3|      3110|            0|    1997|           0|   11224 SE 306th Pl|          Auburn|WA 98092|    USA|             -1997.0|    5|        18|2014|\n",
      "|2014-05-02 00:00:00| 257950.0|     3.0|     1.75|       1370|    5858|   1.0|         0|   0|        3|      1370|            0|    1987|        2000|     1605 S 245th Pl|      Des Moines|WA 98198|    USA|                13.0|    5|        18|2014|\n",
      "|2014-05-02 00:00:00| 275000.0|     3.0|      1.5|       1180|   10277|   1.0|         0|   0|        3|      1180|            0|    1983|        2009|  12425 415th Ave SE|      North Bend|WA 98045|    USA|                26.0|    5|        18|2014|\n",
      "+-------------------+---------+--------+---------+-----------+--------+------+----------+----+---------+----------+-------------+--------+------------+--------------------+----------------+--------+-------+--------------------+-----+----------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|avg(year)|\n",
      "+---------+\n",
      "|   2014.0|\n",
      "|   2014.0|\n",
      "|   2014.0|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('month').mean().select(['avg(year)']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------------+----------+------------------+---------+\n",
      "|month|avg(yr_before_renovation)|avg(month)|   avg(weekofyear)|avg(year)|\n",
      "+-----+-------------------------+----------+------------------+---------+\n",
      "|    6|      -1157.9550252409363|       6.0|24.719137218907758|   2014.0|\n",
      "|    5|      -1143.7516968325792|       5.0|20.362556561085974|   2014.0|\n",
      "|    7|      -1226.1592649310874|       7.0| 27.55436447166922|   2014.0|\n",
      "+-----+-------------------------+----------+------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('month').mean().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+---------+\n",
      "|avg(month)|   avg(weekofyear)|avg(year)|\n",
      "+----------+------------------+---------+\n",
      "|       6.0|24.719137218907758|   2014.0|\n",
      "|       5.0|20.362556561085974|   2014.0|\n",
      "|       7.0| 27.55436447166922|   2014.0|\n",
      "+----------+------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "month_grouped = df.groupBy('month').mean().select(['avg(month)', 'avg(weekofyear)', 'avg(year)'])\n",
    "month_grouped.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+--------+\n",
      "|avg(year)|avg_week|avg_year|\n",
      "+---------+--------+--------+\n",
      "|   2014.0|   24.72|2,014.00|\n",
      "|   2014.0|   20.36|2,014.00|\n",
      "|   2014.0|   27.55|2,014.00|\n",
      "+---------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "month_grouped.select(['avg(year)', format_number('avg(weekofyear)', 2).alias('avg_week'),\n",
    "                      format_number('avg(year)', 2).alias('avg_year')]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark Walmart Data Analysis Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+------------------+------------------+------------------+--------+------------------+\n",
      "|               Date|              Open|              High|               Low|             Close|  Volume|         Adj Close|\n",
      "+-------------------+------------------+------------------+------------------+------------------+--------+------------------+\n",
      "|2012-01-03 00:00:00|         59.970001|         61.060001|         59.869999|         60.330002|12668800|52.619234999999996|\n",
      "|2012-01-04 00:00:00|60.209998999999996|         60.349998|         59.470001|59.709998999999996| 9593300|         52.078475|\n",
      "|2012-01-05 00:00:00|         59.349998|         59.619999|         58.369999|         59.419998|12768200|         51.825539|\n",
      "|2012-01-06 00:00:00|         59.419998|         59.450001|         58.869999|              59.0| 8069400|          51.45922|\n",
      "|2012-01-09 00:00:00|         59.029999|         59.549999|         58.919998|             59.18| 6679300|51.616215000000004|\n",
      "|2012-01-10 00:00:00|             59.43|59.709998999999996|             58.98|59.040001000000004| 6907300|         51.494109|\n",
      "|2012-01-11 00:00:00|         59.060001|         59.529999|59.040001000000004|         59.400002| 6365600|         51.808098|\n",
      "|2012-01-12 00:00:00|59.790001000000004|              60.0|         59.400002|              59.5| 7236400|51.895315999999994|\n",
      "|2012-01-13 00:00:00|             59.18|59.610001000000004|59.009997999999996|59.540001000000004| 7729300|51.930203999999996|\n",
      "|2012-01-17 00:00:00|         59.869999|60.110001000000004|             59.52|         59.849998| 8500000|         52.200581|\n",
      "|2012-01-18 00:00:00|59.790001000000004|         60.029999|         59.650002|60.009997999999996| 5911400|         52.340131|\n",
      "|2012-01-19 00:00:00|             59.93|             60.73|             59.75|60.610001000000004| 9234600|         52.863447|\n",
      "|2012-01-20 00:00:00|             60.75|             61.25|         60.669998|61.009997999999996|10378800|53.212320999999996|\n",
      "|2012-01-23 00:00:00|         60.810001|             60.98|60.509997999999996|             60.91| 7134100|         53.125104|\n",
      "|2012-01-24 00:00:00|             60.75|              62.0|             60.75|61.389998999999996| 7362800| 53.54375400000001|\n",
      "|2012-01-25 00:00:00|             61.18|61.610001000000004|61.040001000000004|         61.470001| 5915800| 53.61353100000001|\n",
      "|2012-01-26 00:00:00|         61.799999|             61.84|             60.77|         60.970001| 7436200|         53.177436|\n",
      "|2012-01-27 00:00:00|60.860001000000004|         61.119999|60.540001000000004|60.709998999999996| 6287300|         52.950665|\n",
      "|2012-01-30 00:00:00|         60.470001|             61.32|         60.349998|         61.299999| 7636900|53.465256999999994|\n",
      "|2012-01-31 00:00:00|         61.529999|             61.57|         60.580002|61.360001000000004| 9761500|53.517590000000006|\n",
      "+-------------------+------------------+------------------+------------------+------------------+--------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_walmart = spark.read.csv('walmart.csv', inferSchema=True, header=True)\n",
    "\n",
    "df_walmart.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close']"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_walmart.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Volume: integer (nullable = true)\n",
      " |-- Adj Close: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_walmart.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Date=datetime.datetime(2012, 1, 3, 0, 0), Open=59.970001, High=61.060001, Low=59.869999, Close=60.330002, Volume=12668800, Adj Close=52.619234999999996),\n",
       " Row(Date=datetime.datetime(2012, 1, 4, 0, 0), Open=60.209998999999996, High=60.349998, Low=59.470001, Close=59.709998999999996, Volume=9593300, Adj Close=52.078475),\n",
       " Row(Date=datetime.datetime(2012, 1, 5, 0, 0), Open=59.349998, High=59.619999, Low=58.369999, Close=59.419998, Volume=12768200, Adj Close=51.825539),\n",
       " Row(Date=datetime.datetime(2012, 1, 6, 0, 0), Open=59.419998, High=59.450001, Low=58.869999, Close=59.0, Volume=8069400, Adj Close=51.45922),\n",
       " Row(Date=datetime.datetime(2012, 1, 9, 0, 0), Open=59.029999, High=59.549999, Low=58.919998, Close=59.18, Volume=6679300, Adj Close=51.616215000000004)]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_walmart.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
      "|summary|              Open|             High|              Low|            Close|           Volume|        Adj Close|\n",
      "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
      "|  count|              1258|             1258|             1258|             1258|             1258|             1258|\n",
      "|   mean| 72.35785375357709|72.83938807631165| 71.9186009594594|72.38844998012726|8222093.481717011|67.23883848728146|\n",
      "| stddev|  6.76809024470826|6.768186808159218|6.744075756255496|6.756859163732991|  4519780.8431556|6.722609449996857|\n",
      "|    min|56.389998999999996|        57.060001|        56.299999|        56.419998|          2094900|        50.363689|\n",
      "|    max|         90.800003|        90.970001|            89.25|        90.470001|         80898100|84.91421600000001|\n",
      "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_walmart.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
      "|summary|              Open|             High|              Low|            Close|           Volume|        Adj Close|\n",
      "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
      "|  count|              1258|             1258|             1258|             1258|             1258|             1258|\n",
      "|   mean| 72.35785375357709|72.83938807631165| 71.9186009594594|72.38844998012726|8222093.481717011|67.23883848728146|\n",
      "| stddev|  6.76809024470826|6.768186808159218|6.744075756255496|6.756859163732991|  4519780.8431556|6.722609449996857|\n",
      "|    min|56.389998999999996|        57.060001|        56.299999|        56.419998|          2094900|        50.363689|\n",
      "|    max|         90.800003|        90.970001|            89.25|        90.470001|         80898100|84.91421600000001|\n",
      "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summary_stats = df_walmart.describe()\n",
    "summary_stats.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['summary', 'Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close']"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_stats.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------+--------+--------+-------------+---------+\n",
      "|summary|    Open|    High|     Low|   Close|       Volume|Adj Close|\n",
      "+-------+--------+--------+--------+--------+-------------+---------+\n",
      "|  count|1,258.00|1,258.00|1,258.00|1,258.00|     1,258.00| 1,258.00|\n",
      "|   mean|   72.36|   72.84|   71.92|   72.39| 8,222,093.50|    67.24|\n",
      "| stddev|    6.77|    6.77|    6.74|    6.76| 4,519,781.00|     6.72|\n",
      "|    min|   56.39|   57.06|   56.30|   56.42| 2,094,900.00|    50.36|\n",
      "|    max|   90.80|   90.97|   89.25|   90.47|80,898,096.00|    84.91|\n",
      "+-------+--------+--------+--------+--------+-------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summary_stats.select(summary_stats['summary'], format_number(summary_stats['Open'].cast('float'), 2).alias('Open'),\n",
    "                    format_number(summary_stats['High'].cast('float'), 2).alias('High'),\n",
    "                    format_number(summary_stats['Low'].cast('float'), 2).alias('Low'),\n",
    "                    format_number(summary_stats['Close'].cast('float'), 2).alias('Close'),\n",
    "                    format_number(summary_stats['Volume'].cast('float'), 2).alias('Volume'),\n",
    "                    format_number(summary_stats['Adj Close'].cast('float'), 2).alias('Adj Close'),\n",
    "                    ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+------------------+------------------+------------------+--------+------------------+------------------+\n",
      "|               Date|              Open|              High|               Low|             Close|  Volume|         Adj Close|          HV Ratio|\n",
      "+-------------------+------------------+------------------+------------------+------------------+--------+------------------+------------------+\n",
      "|2012-01-03 00:00:00|         59.970001|         61.060001|         59.869999|         60.330002|12668800|52.619234999999996|207481.16266817617|\n",
      "|2012-01-04 00:00:00|60.209998999999996|         60.349998|         59.470001|59.709998999999996| 9593300|         52.078475| 158961.0657485026|\n",
      "|2012-01-05 00:00:00|         59.349998|         59.619999|         58.369999|         59.419998|12768200|         51.825539|214159.68155249383|\n",
      "|2012-01-06 00:00:00|         59.419998|         59.450001|         58.869999|              59.0| 8069400|          51.45922|135734.22816258657|\n",
      "|2012-01-09 00:00:00|         59.029999|         59.549999|         58.919998|             59.18| 6679300|51.616215000000004|112162.89021264299|\n",
      "|2012-01-10 00:00:00|             59.43|59.709998999999996|             58.98|59.040001000000004| 6907300|         51.494109|115680.79242473276|\n",
      "|2012-01-11 00:00:00|         59.060001|         59.529999|59.040001000000004|         59.400002| 6365600|         51.808098| 106930.9609764986|\n",
      "|2012-01-12 00:00:00|59.790001000000004|              60.0|         59.400002|              59.5| 7236400|51.895315999999994|120606.66666666667|\n",
      "|2012-01-13 00:00:00|             59.18|59.610001000000004|59.009997999999996|59.540001000000004| 7729300|51.930203999999996|129664.48364931246|\n",
      "|2012-01-17 00:00:00|         59.869999|60.110001000000004|             59.52|         59.849998| 8500000|         52.200581|141407.41737801666|\n",
      "|2012-01-18 00:00:00|59.790001000000004|         60.029999|         59.650002|60.009997999999996| 5911400|         52.340131|  98474.0979256055|\n",
      "|2012-01-19 00:00:00|             59.93|             60.73|             59.75|60.610001000000004| 9234600|         52.863447|152059.93742795984|\n",
      "|2012-01-20 00:00:00|             60.75|             61.25|         60.669998|61.009997999999996|10378800|53.212320999999996|169449.79591836734|\n",
      "|2012-01-23 00:00:00|         60.810001|             60.98|60.509997999999996|             60.91| 7134100|         53.125104| 116990.8166612004|\n",
      "|2012-01-24 00:00:00|             60.75|              62.0|             60.75|61.389998999999996| 7362800| 53.54375400000001|118754.83870967742|\n",
      "|2012-01-25 00:00:00|             61.18|61.610001000000004|61.040001000000004|         61.470001| 5915800| 53.61353100000001| 96020.12504430895|\n",
      "|2012-01-26 00:00:00|         61.799999|             61.84|             60.77|         60.970001| 7436200|         53.177436| 120249.0297542044|\n",
      "|2012-01-27 00:00:00|60.860001000000004|         61.119999|60.540001000000004|60.709998999999996| 6287300|         52.950665|102868.12995530317|\n",
      "|2012-01-30 00:00:00|         60.470001|             61.32|         60.349998|         61.299999| 7636900|53.465256999999994|124541.74820613177|\n",
      "|2012-01-31 00:00:00|         61.529999|             61.57|         60.580002|61.360001000000004| 9761500|53.517590000000006| 158543.1216501543|\n",
      "+-------------------+------------------+------------------+------------------+------------------+--------+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a column called HV Ratio which is the ratio of the High Price versus volume of stock traded for a day\n",
    "df_walmart.withColumn('HV Ratio', df_walmart['Volume']/df_walmart['High']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            HV Ratio|\n",
      "+--------------------+\n",
      "|4.819714653321546E-6|\n",
      "|6.290848613094555E-6|\n",
      "|4.669412994783916E-6|\n",
      "|7.367338463826307E-6|\n",
      "|8.915604778943901E-6|\n",
      "|8.644477436914568E-6|\n",
      "|9.351828421515645E-6|\n",
      "| 8.29141562102703E-6|\n",
      "|7.712212102001476E-6|\n",
      "|7.071764823529412E-6|\n",
      "|1.015495466386981E-5|\n",
      "|6.576354146362592...|\n",
      "| 5.90145296180676E-6|\n",
      "|8.547679455011844E-6|\n",
      "|8.420709512685392E-6|\n",
      "|1.041448341728929...|\n",
      "|8.316075414862431E-6|\n",
      "|9.721183814992126E-6|\n",
      "|8.029436027707578E-6|\n",
      "|6.307432259386365E-6|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_hv_ratio = df_walmart.withColumn('HV Ratio', df_walmart['High']/df_walmart['Volume']).select('HV Ratio')\n",
    "df_hv_ratio.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2015, 1, 13, 0, 0)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what day had the Peak High in Price\n",
    "from pyspark.sql.functions import max as maxx\n",
    "df_walmart.orderBy(df_walmart['High'].desc()).select(['Date']).head(1)[0]['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|Mean Close|\n",
      "+----------+\n",
      "|     72.39|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# what is the mean of the Close column?\n",
    "from pyspark.sql.functions import mean\n",
    "df_walmart.select(format_number(mean('Close'), 2).alias('Mean Close')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------+\n",
      "|Max Volume Value|Min Volume Value|\n",
      "+----------------+----------------+\n",
      "|   80,898,100.00|    2,094,900.00|\n",
      "+----------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# what is the max and min of the Volume column?\n",
    "from pyspark.sql.functions import min as minn\n",
    "df_walmart.select([format_number(maxx('Volume'), 2).alias('Max Volume Value'), format_number(minn('Volume'), 2).alias('Min Volume Value')]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many days was the Close lower than 60 dollars\n",
    "df_walmart.createOrReplaceTempView('walmart_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|No_of_days|\n",
      "+----------+\n",
      "|        81|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT count(*) AS No_of_days\n",
    "        FROM walmart_data\n",
    "            WHERE Close < 60\n",
    "    \n",
    "    \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.141494435612083"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What percentage of the time was the High greater than 80 dollars\n",
    "df_walmart.filter('High > 80').count() / df_walmart.count() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3384326061737161"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is the pearson correlation between High and Volume?\n",
    "df_walmart.corr('High', 'Volume')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.38206212516421384"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_walmart.corr('Volume', 'Low')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9975558445796231"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_walmart.corr('Low', 'High')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+------------------+------------------+------------------+--------+------------------+----+\n",
      "|               Date|              Open|              High|               Low|             Close|  Volume|         Adj Close|Year|\n",
      "+-------------------+------------------+------------------+------------------+------------------+--------+------------------+----+\n",
      "|2012-01-03 00:00:00|         59.970001|         61.060001|         59.869999|         60.330002|12668800|52.619234999999996|2012|\n",
      "|2012-01-04 00:00:00|60.209998999999996|         60.349998|         59.470001|59.709998999999996| 9593300|         52.078475|2012|\n",
      "|2012-01-05 00:00:00|         59.349998|         59.619999|         58.369999|         59.419998|12768200|         51.825539|2012|\n",
      "|2012-01-06 00:00:00|         59.419998|         59.450001|         58.869999|              59.0| 8069400|          51.45922|2012|\n",
      "|2012-01-09 00:00:00|         59.029999|         59.549999|         58.919998|             59.18| 6679300|51.616215000000004|2012|\n",
      "|2012-01-10 00:00:00|             59.43|59.709998999999996|             58.98|59.040001000000004| 6907300|         51.494109|2012|\n",
      "|2012-01-11 00:00:00|         59.060001|         59.529999|59.040001000000004|         59.400002| 6365600|         51.808098|2012|\n",
      "|2012-01-12 00:00:00|59.790001000000004|              60.0|         59.400002|              59.5| 7236400|51.895315999999994|2012|\n",
      "|2012-01-13 00:00:00|             59.18|59.610001000000004|59.009997999999996|59.540001000000004| 7729300|51.930203999999996|2012|\n",
      "|2012-01-17 00:00:00|         59.869999|60.110001000000004|             59.52|         59.849998| 8500000|         52.200581|2012|\n",
      "|2012-01-18 00:00:00|59.790001000000004|         60.029999|         59.650002|60.009997999999996| 5911400|         52.340131|2012|\n",
      "|2012-01-19 00:00:00|             59.93|             60.73|             59.75|60.610001000000004| 9234600|         52.863447|2012|\n",
      "|2012-01-20 00:00:00|             60.75|             61.25|         60.669998|61.009997999999996|10378800|53.212320999999996|2012|\n",
      "|2012-01-23 00:00:00|         60.810001|             60.98|60.509997999999996|             60.91| 7134100|         53.125104|2012|\n",
      "|2012-01-24 00:00:00|             60.75|              62.0|             60.75|61.389998999999996| 7362800| 53.54375400000001|2012|\n",
      "|2012-01-25 00:00:00|             61.18|61.610001000000004|61.040001000000004|         61.470001| 5915800| 53.61353100000001|2012|\n",
      "|2012-01-26 00:00:00|         61.799999|             61.84|             60.77|         60.970001| 7436200|         53.177436|2012|\n",
      "|2012-01-27 00:00:00|60.860001000000004|         61.119999|60.540001000000004|60.709998999999996| 6287300|         52.950665|2012|\n",
      "|2012-01-30 00:00:00|         60.470001|             61.32|         60.349998|         61.299999| 7636900|53.465256999999994|2012|\n",
      "|2012-01-31 00:00:00|         61.529999|             61.57|         60.580002|61.360001000000004| 9761500|53.517590000000006|2012|\n",
      "+-------------------+------------------+------------------+------------------+------------------+--------+------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# what is the max High per year\n",
    "df_walmart_year = df_walmart.withColumn('Year', year(df_walmart['Date']))\n",
    "\n",
    "df_walmart_year.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o3060.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 402.0 failed 1 times, most recent failure: Lost task 0.0 in stage 402.0 (TID 5975, localhost, executor driver): java.io.FileNotFoundException: C:\\Users\\ABUTON\\AppData\\Local\\Temp\\blockmgr-b0b89f37-38bf-4ed3-8cfe-831d8508f8c7\\2f\\temp_shuffle_62e93f51-9856-4622-80e4-4591271d023d (The system cannot find the path specified)\r\n\tat java.io.FileOutputStream.open0(Native Method)\r\n\tat java.io.FileOutputStream.open(Unknown Source)\r\n\tat java.io.FileOutputStream.<init>(Unknown Source)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.initialize(DiskBlockObjectWriter.scala:103)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:116)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:237)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.lang.Thread.run(Unknown Source)\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)\r\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\r\n\tat scala.Option.foreach(Option.scala:257)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:365)\r\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:38)\r\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3389)\r\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2550)\r\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2550)\r\n\tat org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3370)\r\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:78)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)\r\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3369)\r\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2550)\r\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2764)\r\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:254)\r\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:291)\r\n\tat sun.reflect.GeneratedMethodAccessor57.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\r\n\tat java.lang.reflect.Method.invoke(Unknown Source)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: java.io.FileNotFoundException: C:\\Users\\ABUTON\\AppData\\Local\\Temp\\blockmgr-b0b89f37-38bf-4ed3-8cfe-831d8508f8c7\\2f\\temp_shuffle_62e93f51-9856-4622-80e4-4591271d023d (The system cannot find the path specified)\r\n\tat java.io.FileOutputStream.open0(Native Method)\r\n\tat java.io.FileOutputStream.open(Unknown Source)\r\n\tat java.io.FileOutputStream.<init>(Unknown Source)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.initialize(DiskBlockObjectWriter.scala:103)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:116)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:237)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\t... 1 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-267-a0e4391ffb4a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# group By Year\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf_walmart_year\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupBy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Year'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\spark\\spark-2.4.4-bin-hadoop2.7\\python\\pyspark\\sql\\dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[1;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[0;32m    378\u001b[0m         \"\"\"\n\u001b[0;32m    379\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\spark\\spark-2.4.4-bin-hadoop2.7\\python\\lib\\py4j-0.10.7-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m-> 1257\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m   1258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1259\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\spark\\spark-2.4.4-bin-hadoop2.7\\python\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\spark\\spark-2.4.4-bin-hadoop2.7\\python\\lib\\py4j-0.10.7-src.zip\\py4j\\protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[0;32m    327\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[0;32m    329\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o3060.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 402.0 failed 1 times, most recent failure: Lost task 0.0 in stage 402.0 (TID 5975, localhost, executor driver): java.io.FileNotFoundException: C:\\Users\\ABUTON\\AppData\\Local\\Temp\\blockmgr-b0b89f37-38bf-4ed3-8cfe-831d8508f8c7\\2f\\temp_shuffle_62e93f51-9856-4622-80e4-4591271d023d (The system cannot find the path specified)\r\n\tat java.io.FileOutputStream.open0(Native Method)\r\n\tat java.io.FileOutputStream.open(Unknown Source)\r\n\tat java.io.FileOutputStream.<init>(Unknown Source)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.initialize(DiskBlockObjectWriter.scala:103)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:116)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:237)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.lang.Thread.run(Unknown Source)\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)\r\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\r\n\tat scala.Option.foreach(Option.scala:257)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:365)\r\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:38)\r\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3389)\r\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2550)\r\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2550)\r\n\tat org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3370)\r\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:78)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)\r\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3369)\r\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2550)\r\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2764)\r\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:254)\r\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:291)\r\n\tat sun.reflect.GeneratedMethodAccessor57.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\r\n\tat java.lang.reflect.Method.invoke(Unknown Source)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: java.io.FileNotFoundException: C:\\Users\\ABUTON\\AppData\\Local\\Temp\\blockmgr-b0b89f37-38bf-4ed3-8cfe-831d8508f8c7\\2f\\temp_shuffle_62e93f51-9856-4622-80e4-4591271d023d (The system cannot find the path specified)\r\n\tat java.io.FileOutputStream.open0(Native Method)\r\n\tat java.io.FileOutputStream.open(Unknown Source)\r\n\tat java.io.FileOutputStream.<init>(Unknown Source)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.initialize(DiskBlockObjectWriter.scala:103)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:116)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:237)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\t... 1 more\r\n"
     ]
    }
   ],
   "source": [
    "# group By Year\n",
    "df_walmart_year.groupBy('Year').max()['Year', 'max(High)'].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|month|\n",
      "+-----+\n",
      "|    1|\n",
      "|    1|\n",
      "|    1|\n",
      "|    1|\n",
      "|    1|\n",
      "|    1|\n",
      "|    1|\n",
      "|    1|\n",
      "|    1|\n",
      "|    1|\n",
      "|    1|\n",
      "|    1|\n",
      "|    1|\n",
      "|    1|\n",
      "|    1|\n",
      "|    1|\n",
      "|    1|\n",
      "|    1|\n",
      "|    1|\n",
      "|    1|\n",
      "+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_month = df_walmart.withColumn('month', month(df_walmart['Date']))\n",
    "df_month.select('month').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o3265.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 410.0 failed 1 times, most recent failure: Lost task 0.0 in stage 410.0 (TID 5980, localhost, executor driver): java.io.FileNotFoundException: C:\\Users\\ABUTON\\AppData\\Local\\Temp\\blockmgr-b0b89f37-38bf-4ed3-8cfe-831d8508f8c7\\26\\temp_shuffle_c4597521-f920-4c58-933a-394566b2b478 (The system cannot find the path specified)\r\n\tat java.io.FileOutputStream.open0(Native Method)\r\n\tat java.io.FileOutputStream.open(Unknown Source)\r\n\tat java.io.FileOutputStream.<init>(Unknown Source)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.initialize(DiskBlockObjectWriter.scala:103)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:116)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:237)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.lang.Thread.run(Unknown Source)\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)\r\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\r\n\tat scala.Option.foreach(Option.scala:257)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:365)\r\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:38)\r\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3389)\r\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2550)\r\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2550)\r\n\tat org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3370)\r\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:78)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)\r\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3369)\r\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2550)\r\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2764)\r\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:254)\r\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:291)\r\n\tat sun.reflect.GeneratedMethodAccessor57.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\r\n\tat java.lang.reflect.Method.invoke(Unknown Source)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: java.io.FileNotFoundException: C:\\Users\\ABUTON\\AppData\\Local\\Temp\\blockmgr-b0b89f37-38bf-4ed3-8cfe-831d8508f8c7\\26\\temp_shuffle_c4597521-f920-4c58-933a-394566b2b478 (The system cannot find the path specified)\r\n\tat java.io.FileOutputStream.open0(Native Method)\r\n\tat java.io.FileOutputStream.open(Unknown Source)\r\n\tat java.io.FileOutputStream.<init>(Unknown Source)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.initialize(DiskBlockObjectWriter.scala:103)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:116)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:237)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\t... 1 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-276-748d3d1c2e13>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# what is the average Close for each Calender Month??\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf_month\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupBy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'month'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mavg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'month'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'avg(Close)'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\spark\\spark-2.4.4-bin-hadoop2.7\\python\\pyspark\\sql\\dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[1;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[0;32m    378\u001b[0m         \"\"\"\n\u001b[0;32m    379\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\spark\\spark-2.4.4-bin-hadoop2.7\\python\\lib\\py4j-0.10.7-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m-> 1257\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m   1258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1259\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\spark\\spark-2.4.4-bin-hadoop2.7\\python\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\spark\\spark-2.4.4-bin-hadoop2.7\\python\\lib\\py4j-0.10.7-src.zip\\py4j\\protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[0;32m    327\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[0;32m    329\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o3265.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 410.0 failed 1 times, most recent failure: Lost task 0.0 in stage 410.0 (TID 5980, localhost, executor driver): java.io.FileNotFoundException: C:\\Users\\ABUTON\\AppData\\Local\\Temp\\blockmgr-b0b89f37-38bf-4ed3-8cfe-831d8508f8c7\\26\\temp_shuffle_c4597521-f920-4c58-933a-394566b2b478 (The system cannot find the path specified)\r\n\tat java.io.FileOutputStream.open0(Native Method)\r\n\tat java.io.FileOutputStream.open(Unknown Source)\r\n\tat java.io.FileOutputStream.<init>(Unknown Source)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.initialize(DiskBlockObjectWriter.scala:103)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:116)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:237)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.lang.Thread.run(Unknown Source)\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)\r\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\r\n\tat scala.Option.foreach(Option.scala:257)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:365)\r\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:38)\r\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3389)\r\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2550)\r\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2550)\r\n\tat org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3370)\r\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:78)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)\r\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3369)\r\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2550)\r\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2764)\r\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:254)\r\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:291)\r\n\tat sun.reflect.GeneratedMethodAccessor57.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\r\n\tat java.lang.reflect.Method.invoke(Unknown Source)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: java.io.FileNotFoundException: C:\\Users\\ABUTON\\AppData\\Local\\Temp\\blockmgr-b0b89f37-38bf-4ed3-8cfe-831d8508f8c7\\26\\temp_shuffle_c4597521-f920-4c58-933a-394566b2b478 (The system cannot find the path specified)\r\n\tat java.io.FileOutputStream.open0(Native Method)\r\n\tat java.io.FileOutputStream.open(Unknown Source)\r\n\tat java.io.FileOutputStream.<init>(Unknown Source)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.initialize(DiskBlockObjectWriter.scala:103)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:116)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:237)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\t... 1 more\r\n"
     ]
    }
   ],
   "source": [
    "# what is the average Close for each Calender Month??\n",
    "df_month.groupBy('month').avg()['month', 'avg(Close)'].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_month.createOrReplaceTempView('walmart_month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o3362.collectToPython.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 414.0 failed 1 times, most recent failure: Lost task 0.0 in stage 414.0 (TID 5982, localhost, executor driver): java.io.FileNotFoundException: C:\\Users\\ABUTON\\AppData\\Local\\Temp\\blockmgr-b0b89f37-38bf-4ed3-8cfe-831d8508f8c7\\04\\temp_shuffle_5dee045c-5834-4daf-ace0-26604b020473 (The system cannot find the path specified)\r\n\tat java.io.FileOutputStream.open0(Native Method)\r\n\tat java.io.FileOutputStream.open(Unknown Source)\r\n\tat java.io.FileOutputStream.<init>(Unknown Source)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.initialize(DiskBlockObjectWriter.scala:103)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:116)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:237)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.lang.Thread.run(Unknown Source)\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)\r\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\r\n\tat scala.Option.foreach(Option.scala:257)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:944)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:299)\r\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:3263)\r\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:3260)\r\n\tat org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3370)\r\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:78)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)\r\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3369)\r\n\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:3260)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\r\n\tat java.lang.reflect.Method.invoke(Unknown Source)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: java.io.FileNotFoundException: C:\\Users\\ABUTON\\AppData\\Local\\Temp\\blockmgr-b0b89f37-38bf-4ed3-8cfe-831d8508f8c7\\04\\temp_shuffle_5dee045c-5834-4daf-ace0-26604b020473 (The system cannot find the path specified)\r\n\tat java.io.FileOutputStream.open0(Native Method)\r\n\tat java.io.FileOutputStream.open(Unknown Source)\r\n\tat java.io.FileOutputStream.<init>(Unknown Source)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.initialize(DiskBlockObjectWriter.scala:103)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:116)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:237)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\t... 1 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-280-b14f0553abf4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mGROUP\u001b[0m \u001b[0mBY\u001b[0m \u001b[0mmonth\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \"\"\").collect()\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\spark\\spark-2.4.4-bin-hadoop2.7\\python\\pyspark\\sql\\dataframe.py\u001b[0m in \u001b[0;36mcollect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    532\u001b[0m         \"\"\"\n\u001b[0;32m    533\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 534\u001b[1;33m             \u001b[0msock_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollectToPython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    535\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBatchedSerializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPickleSerializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\spark\\spark-2.4.4-bin-hadoop2.7\\python\\lib\\py4j-0.10.7-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m-> 1257\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m   1258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1259\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\spark\\spark-2.4.4-bin-hadoop2.7\\python\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\spark\\spark-2.4.4-bin-hadoop2.7\\python\\lib\\py4j-0.10.7-src.zip\\py4j\\protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[0;32m    327\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[0;32m    329\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o3362.collectToPython.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 414.0 failed 1 times, most recent failure: Lost task 0.0 in stage 414.0 (TID 5982, localhost, executor driver): java.io.FileNotFoundException: C:\\Users\\ABUTON\\AppData\\Local\\Temp\\blockmgr-b0b89f37-38bf-4ed3-8cfe-831d8508f8c7\\04\\temp_shuffle_5dee045c-5834-4daf-ace0-26604b020473 (The system cannot find the path specified)\r\n\tat java.io.FileOutputStream.open0(Native Method)\r\n\tat java.io.FileOutputStream.open(Unknown Source)\r\n\tat java.io.FileOutputStream.<init>(Unknown Source)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.initialize(DiskBlockObjectWriter.scala:103)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:116)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:237)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.lang.Thread.run(Unknown Source)\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)\r\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\r\n\tat scala.Option.foreach(Option.scala:257)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:944)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:299)\r\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:3263)\r\n\tat org.apache.spark.sql.Dataset$$anonfun$collectToPython$1.apply(Dataset.scala:3260)\r\n\tat org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3370)\r\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:78)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)\r\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3369)\r\n\tat org.apache.spark.sql.Dataset.collectToPython(Dataset.scala:3260)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\r\n\tat java.lang.reflect.Method.invoke(Unknown Source)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: java.io.FileNotFoundException: C:\\Users\\ABUTON\\AppData\\Local\\Temp\\blockmgr-b0b89f37-38bf-4ed3-8cfe-831d8508f8c7\\04\\temp_shuffle_5dee045c-5834-4daf-ace0-26604b020473 (The system cannot find the path specified)\r\n\tat java.io.FileOutputStream.open0(Native Method)\r\n\tat java.io.FileOutputStream.open(Unknown Source)\r\n\tat java.io.FileOutputStream.<init>(Unknown Source)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.initialize(DiskBlockObjectWriter.scala:103)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:116)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:237)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\t... 1 more\r\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT month, AVG(Close)\n",
    "        FROM walmart_month\n",
    "        GROUP BY month\n",
    "\n",
    "    \"\"\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_data = df_month.groupBy('month').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_data = month_data.orderBy('month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o3424.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 417.0 failed 1 times, most recent failure: Lost task 0.0 in stage 417.0 (TID 5984, localhost, executor driver): java.io.FileNotFoundException: C:\\Users\\ABUTON\\AppData\\Local\\Temp\\blockmgr-b0b89f37-38bf-4ed3-8cfe-831d8508f8c7\\0d\\temp_shuffle_c8853ce3-1067-4b39-a8cd-53b870dd8a82 (The system cannot find the path specified)\r\n\tat java.io.FileOutputStream.open0(Native Method)\r\n\tat java.io.FileOutputStream.open(Unknown Source)\r\n\tat java.io.FileOutputStream.<init>(Unknown Source)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.initialize(DiskBlockObjectWriter.scala:103)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:116)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:237)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.lang.Thread.run(Unknown Source)\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)\r\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\r\n\tat scala.Option.foreach(Option.scala:257)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2158)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1035)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\r\n\tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1017)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$takeOrdered$1.apply(RDD.scala:1439)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\r\n\tat org.apache.spark.rdd.RDD.takeOrdered(RDD.scala:1426)\r\n\tat org.apache.spark.sql.execution.TakeOrderedAndProjectExec.executeCollect(limit.scala:136)\r\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3389)\r\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2550)\r\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2550)\r\n\tat org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3370)\r\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:78)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)\r\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3369)\r\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2550)\r\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2764)\r\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:254)\r\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:291)\r\n\tat sun.reflect.GeneratedMethodAccessor57.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\r\n\tat java.lang.reflect.Method.invoke(Unknown Source)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: java.io.FileNotFoundException: C:\\Users\\ABUTON\\AppData\\Local\\Temp\\blockmgr-b0b89f37-38bf-4ed3-8cfe-831d8508f8c7\\0d\\temp_shuffle_c8853ce3-1067-4b39-a8cd-53b870dd8a82 (The system cannot find the path specified)\r\n\tat java.io.FileOutputStream.open0(Native Method)\r\n\tat java.io.FileOutputStream.open(Unknown Source)\r\n\tat java.io.FileOutputStream.<init>(Unknown Source)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.initialize(DiskBlockObjectWriter.scala:103)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:116)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:237)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\t... 1 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-284-8bcd8a5e833f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmonth_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'month'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'avg(Close)'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\spark\\spark-2.4.4-bin-hadoop2.7\\python\\pyspark\\sql\\dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[1;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[0;32m    378\u001b[0m         \"\"\"\n\u001b[0;32m    379\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\spark\\spark-2.4.4-bin-hadoop2.7\\python\\lib\\py4j-0.10.7-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m-> 1257\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m   1258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1259\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\spark\\spark-2.4.4-bin-hadoop2.7\\python\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\spark\\spark-2.4.4-bin-hadoop2.7\\python\\lib\\py4j-0.10.7-src.zip\\py4j\\protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[0;32m    327\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[0;32m    329\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o3424.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 417.0 failed 1 times, most recent failure: Lost task 0.0 in stage 417.0 (TID 5984, localhost, executor driver): java.io.FileNotFoundException: C:\\Users\\ABUTON\\AppData\\Local\\Temp\\blockmgr-b0b89f37-38bf-4ed3-8cfe-831d8508f8c7\\0d\\temp_shuffle_c8853ce3-1067-4b39-a8cd-53b870dd8a82 (The system cannot find the path specified)\r\n\tat java.io.FileOutputStream.open0(Native Method)\r\n\tat java.io.FileOutputStream.open(Unknown Source)\r\n\tat java.io.FileOutputStream.<init>(Unknown Source)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.initialize(DiskBlockObjectWriter.scala:103)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:116)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:237)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.lang.Thread.run(Unknown Source)\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876)\r\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\r\n\tat scala.Option.foreach(Option.scala:257)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2158)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1035)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\r\n\tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1017)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$takeOrdered$1.apply(RDD.scala:1439)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\r\n\tat org.apache.spark.rdd.RDD.takeOrdered(RDD.scala:1426)\r\n\tat org.apache.spark.sql.execution.TakeOrderedAndProjectExec.executeCollect(limit.scala:136)\r\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:3389)\r\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2550)\r\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2550)\r\n\tat org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3370)\r\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:78)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)\r\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3369)\r\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2550)\r\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2764)\r\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:254)\r\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:291)\r\n\tat sun.reflect.GeneratedMethodAccessor57.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\r\n\tat java.lang.reflect.Method.invoke(Unknown Source)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: java.io.FileNotFoundException: C:\\Users\\ABUTON\\AppData\\Local\\Temp\\blockmgr-b0b89f37-38bf-4ed3-8cfe-831d8508f8c7\\0d\\temp_shuffle_c8853ce3-1067-4b39-a8cd-53b870dd8a82 (The system cannot find the path specified)\r\n\tat java.io.FileOutputStream.open0(Native Method)\r\n\tat java.io.FileOutputStream.open(Unknown Source)\r\n\tat java.io.FileOutputStream.<init>(Unknown Source)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.initialize(DiskBlockObjectWriter.scala:103)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.open(DiskBlockObjectWriter.scala:116)\r\n\tat org.apache.spark.storage.DiskBlockObjectWriter.write(DiskBlockObjectWriter.scala:237)\r\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:151)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\t... 1 more\r\n"
     ]
    }
   ],
   "source": [
    "month_data['month', 'avg(Close)'].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
